{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRMIA_DL_Summer_school_2022_Object_Detection_with_YOLO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DL IRMIA summer school : Object Detection with YOLO"
      ],
      "metadata": {
        "id": "0ZqgJPXRWFgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction - Notebook Setup\n"
      ],
      "metadata": {
        "id": "uz7N4sQtedH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"repo_cloning\"></a>\n",
        "### 1\\. Clone the associated Git repository"
      ],
      "metadata": {
        "id": "6GSYAKkTd7Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/Deyht/IRMIA_2022\n",
        "\n",
        "mkdir /content/IRMIA_2022/pre_trained_nets/\n",
        "cd /content/IRMIA_2022/pre_trained_nets/\n",
        "wget https://share.obspm.fr/s/SKedZBnGnioHkiL/download/pre_trained_nets.tar.gz\n",
        "tar -xvzf pre_trained_nets.tar.gz\n"
      ],
      "metadata": {
        "id": "rW8gwTyHd7zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"data_download\"></a>\n",
        "### 2\\. PASCAL VOC 2012 and 2007\n",
        "\n"
      ],
      "metadata": {
        "id": "cKGTBYPxdS-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Dataset download\n"
      ],
      "metadata": {
        "id": "9NqfAfh7FLdc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "704uuUNvZ43G"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "cd IRMIA_2022/\n",
        "\n",
        "mkdir dataset\n",
        "cd dataset\n",
        "\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "tar -xf VOCtrainval_11-May-2012.tar\n",
        "tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "tar -xf VOCtest_06-Nov-2007.tar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"data_format\"></a>\n",
        "#### Format dataset"
      ],
      "metadata": {
        "id": "AK_pxCkv2i9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/dataset/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def make_square(im, min_size, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    size = max(min_size, x, y)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "forced_regen = True\n",
        "\n",
        "if(not os.path.exists('./all_im.dat') or forced_regen):\n",
        "\t\tall_im = np.zeros((orig_nb_images, image_size, image_size, 3), dtype=\"uint8\")\n",
        "\t\tall_im_prop = np.zeros((orig_nb_images, 4), dtype=\"float32\")\n",
        "\n",
        "\t\tfor i in tqdm(range(0, orig_nb_images)):\n",
        "\n",
        "\t\t\tif(i < nb_train_2007):\n",
        "\t\t\t\tim = Image.open(\"VOCdevkit/VOC2007/JPEGImages/\"+train_list_2007[i]+\".jpg\")\n",
        "\t\t\telif(i < nb_train_2007+nb_test_2007):\n",
        "\t\t\t\tim = Image.open(\"VOCdevkit/VOC2007/JPEGImages/\"+test_list_2007[i - nb_train_2007]+\".jpg\")\n",
        "\t\t\telse:\n",
        "\t\t\t\tim = Image.open(\"VOCdevkit/VOC2012/JPEGImages/\"+train_list_2012[i - nb_train_2007 - nb_test_2007]+\".jpg\")\n",
        "\t\t\t\n",
        "\t\t\twidth, height = im.size\n",
        "\n",
        "\t\t\tim = make_square(im, image_size)\n",
        "\t\t\twidth2, height2 = im.size\n",
        "\n",
        "\t\t\tx_offset = int((width2 - width)*0.5)\n",
        "\t\t\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\t\t\tall_im_prop[i] = [x_offset, y_offset, width2, height2]\n",
        "\n",
        "\t\t\tim = im.resize((image_size,image_size))\n",
        "\t\t\tim_array = np.asarray(im)\n",
        "\t\t\tfor depth in range(0,3):\n",
        "\t\t\t\tall_im[i,:,:,depth] = im_array[:,:,depth]\n",
        "\n",
        "\t\tall_im.tofile(\"all_im.dat\")\n",
        "\t\tall_im_prop.tofile(\"all_im_prop.dat\")"
      ],
      "metadata": {
        "id": "VFxmRmpha4LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset summary statistics"
      ],
      "metadata": {
        "id": "4zsMWlIwFa8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 1000 #keep in 2012 trainval\n",
        "\n",
        "nb_class = 20\n",
        "image_size = 224\n",
        "\n",
        "object_list = np.zeros((orig_nb_images,1+nb_class))\n",
        "\n",
        "for i_d in tqdm(range(0, orig_nb_images)):\n",
        "\t\n",
        "  if(i_d < nb_train_2007):\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d]+\".xml\")\n",
        "  elif(i_d < nb_train_2007+nb_test_2007):\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2007]+\".xml\")\n",
        "  else:\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d - nb_train_2007 - nb_test_2007]+\".xml\")\n",
        "\n",
        "  root = tree.getroot()\n",
        "\n",
        "  k = 0\n",
        "  im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "  object_list[i_d,0] = len(im_obj_list)\n",
        "  for obj in im_obj_list:\n",
        "    diff = obj.find(\"difficult\", namespaces=None)\n",
        "    if(diff.text == \"1\"):\n",
        "      object_list[i_d,0] -= 1\n",
        "      continue\n",
        "    oclass = obj.find(\"name\", namespaces=None)\n",
        "    int_class = np.where(class_list[:] == oclass.text)[0] + 1\n",
        "    object_list[i_d,int_class] += 1\n",
        "\n",
        "np.savetxt(\"in_image_obj_count.txt\", object_list, fmt=\"%d\", header=\"Total, aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, diningtable, dog, horse, motorbike, person, pottedplant, sheep, sofa, train, tvmonitor\")\n",
        "\n",
        "plt.rcParams.update({'font.size': 6})\n",
        "\n",
        "all_dat = np.sum(object_list[:,1:],axis=0)\n",
        "train_dat = np.sum(object_list[:orig_nb_images-nb_keep_val:,1:],axis=0)\n",
        "val_dat = np.sum(object_list[orig_nb_images-nb_keep_val:,1:],axis=0)\n",
        "\n",
        "print(\"%8s\"%(\"Total\"),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8s\"%class_list_short[k],end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(all_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%all_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(train_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%train_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(val_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%val_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "plt.subplots(figsize=(6,2),dpi=190, constrained_layout=True)\n",
        "plt.bar(np.arange(0,nb_class)-0.2, all_dat, width=-0.2, align=\"center\", label=\"All\")\n",
        "plt.bar(np.arange(0,nb_class), train_dat, width=0.2, align=\"center\", label=\"Train\")\n",
        "plt.bar(np.arange(0,nb_class)+0.2, val_dat, width=0.2, align=\"center\", label=\"Val\")\n",
        "plt.xticks(np.arange(0,nb_class), class_list, fontsize=6, rotation = 45)\n",
        "plt.legend()\n",
        "#plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "all_dat = all_dat / np.max(all_dat)\n",
        "train_dat = train_dat / np.max(train_dat)\n",
        "val_dat = val_dat / np.max(val_dat)\n",
        "\n",
        "plt.subplots(figsize=(6,2),dpi=190, constrained_layout=True)\n",
        "plt.bar(np.arange(0,nb_class)-0.2, all_dat, width=0.2, align=\"center\", label=\"All\")\n",
        "plt.bar(np.arange(0,nb_class), train_dat, width=0.2, align=\"center\", label=\"Train\")\n",
        "plt.bar(np.arange(0,nb_class)+0.2, val_dat, width=0.2, align=\"center\", label=\"Val\")\n",
        "plt.xticks(range(0,nb_class), class_list, fontsize=6, rotation = 45)\n",
        "plt.legend()\n",
        "#plt.yscale('log')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MiR7lpk1Fn64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_im = np.fromfile(\"all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n"
      ],
      "metadata": {
        "id": "d7xBwuRwOOtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_start = 32 #define the beginning of the serie, then display nb_w * nb_h examples\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5.0,0.4), dpi=180, constrained_layout=True)\n",
        "ax.axis('off')\n",
        "fig.patch.set_facecolor('black')\n",
        "\n",
        "for k in range(0, nb_class):\n",
        "\tax.text(k%10*0.12, k//10*0.5, class_list_short[k], color=plt.cm.tab20(k), fontsize=8)\n",
        "\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(6,12), dpi=210, constrained_layout=True)\n",
        "\n",
        "for i in range(0, nb_h):\n",
        "  for j in range(0, nb_w):\n",
        "    i_d = j + i*nb_w + id_start\n",
        "\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images - nb_keep_val + i_d]\n",
        "\n",
        "    c_data = all_im[orig_nb_images - nb_keep_val + i_d]/255.0\n",
        "    ax[i,j].imshow(c_data)\n",
        "    ax[i,j].axis('off')\n",
        "\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2012/Annotations/\"+train_list_2012[nb_train_2012 - nb_keep_val + i_d]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    obj_list = root.findall(\"object\", namespaces=None)\n",
        "    for obj in obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "      int_class = np.where(class_list[:] == oclass.text)[0][0]\n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\n",
        "      el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.8, ls=\"--\", fill=False, color=plt.cm.tab20(int_class), zorder=3)\n",
        "      ax[i,j].add_patch(el)\n",
        "      ax[i,j].text(xmin+2, ymin-3, \"%s\"%(class_list_short[int_class]), c=plt.cm.tab20(int_class), fontsize=6, clip_on=True)\n",
        "\n",
        "plt.savefig(\"target_moisaic.png\", dpi=250)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r31anWFsMBEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"cianna_install\"></a>\n",
        "\n",
        "### 3\\. DL Framework (CIANNA) installation"
      ],
      "metadata": {
        "id": "VcS4X04k4u9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n"
      ],
      "metadata": {
        "id": "bAGWKAMS5JhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /usr/local/cuda/samples/1_Utilities/deviceQuery\n",
        "\n",
        "make \n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository\n",
        "\n",
        "Choice of a specific commit to preserve the notebook from incompatibilty in futur CIANNA updates."
      ],
      "metadata": {
        "id": "OBuyj5WU5p8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA\n",
        "git checkout 62fb3c7"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons CIANNA must be provided the plateform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "uGoKpzlO6cS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "pyth_ver=$(python3 -c 'import sys; print(\"%d.%d\"%(sys.version_info[:][0], sys.version_info[:][1]))')\n",
        "\n",
        "sed -i \"s/\\/lib.linux-x86_64-[0-9].[0-9]/\\/lib.linux-x86_64-$pyth_ver/g\" ex_script.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing CIANNA installation\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. In order to avoid possible errors, every cell code that directly invoke CIANNA functions must be run as a script.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "This allows to easilly edit python code in the notebook, while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "tar -xvzf mnist.tar.gz"
      ],
      "metadata": {
        "id": "zZ_GKLD786w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "#Strictly equivalent to ex_script.py in the CIANNA repo \n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#Uncomment to access a locally compiled version\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "############################################################################\n",
        "##              Data reading (your mileage may vary)\n",
        "############################################################################\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "print (\"Reading inputs ... \", end = \"\", flush=True)\n",
        "\n",
        "#Loading binary files\n",
        "data = np.fromfile(\"mnist_dat/mnist_input.dat\", dtype=\"float32\")\n",
        "data = np.reshape(data, (80000,28*28))\n",
        "target = np.fromfile(\"mnist_dat/mnist_target.dat\", dtype=\"float32\")\n",
        "target = np.reshape(target, (80000,10))\n",
        "\n",
        "\n",
        "data_train = data[:60000,:]\n",
        "data_valid = data[60000:70000,:]\n",
        "data_test  = data[70000:80000,:]\n",
        "\n",
        "target_train = target[:60000,:]\n",
        "target_valid = target[60000:70000,:]\n",
        "target_test  = target[70000:80000,:]\n",
        "\n",
        "print (\"Done !\", flush=True)\n",
        "\n",
        "############################################################################\n",
        "##               CIANNA network construction and use\n",
        "############################################################################\n",
        "\n",
        "#Details about the functions and parameters are given in the GitHub Wiki\n",
        "\n",
        "cnn.init(in_dim=i_ar([28,28]), in_nb_ch=1, out_dim=10, \\\n",
        "\t\tbias=0.1, b_size=24, comp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP16C_FP32A\") #Change to C_BLAS or C_NAIV\n",
        "\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", size=60000, input=data_train, target=target_train)\n",
        "cnn.create_dataset(\"VALID\", size=10000, input=data_valid, target=target_valid)\n",
        "cnn.create_dataset(\"TEST\", size=10000, input=data_test, target=target_test)\n",
        "\n",
        "#del (data_train, target_train, data_valid, target_valid, data_test, target_test)\n",
        "\n",
        "#Used to load a saved network at a given epoch\n",
        "load_step = 0\n",
        "if(load_step > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%(load_step), load_step)\n",
        "else:\n",
        "  cnn.conv(f_size=i_ar([5,5]), nb_filters=32, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([5,5]), nb_filters=64, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.5)\n",
        "  cnn.dense(nb_neurons=128, activation=\"RELU\", drop_rate=0.2)\n",
        "  cnn.dense(nb_neurons=10, activation=\"SMAX\")\n",
        "\n",
        "\n",
        "cnn.train(nb_epoch=10, learning_rate=0.0004, momentum=0.9, confmat=1, save_every=0)\n",
        "#Change save_every in previous function to save network weights\n",
        "cnn.perf_eval()\n",
        "\n",
        "\n",
        "#Uncomment to save network prediction\n",
        "cnn.forward(repeat=1, drop_mode=\"AVG_MODEL\")\n",
        "EOF"
      ],
      "metadata": {
        "id": "2L-7ZffT9Ayq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c1VcemANg-ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A - Simple classifier on PASCAL VOC"
      ],
      "metadata": {
        "id": "J8lC3HBMDdO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\\. Train and valid data generation"
      ],
      "metadata": {
        "id": "Xb_7nGR4EqiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "mkdir classifier\n",
        "cd classifier"
      ],
      "metadata": {
        "id": "YSqToJLcq6nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic data generator"
      ],
      "metadata": {
        "id": "f9fITGtbE0OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/classifier/data_gen.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"../dataset/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"../dataset/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"../dataset/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "def roll_zeropad(a, shift):\n",
        "  a = np.roll(a, shift[0], axis = 1)\n",
        "  if(shift[0] >= 0):\n",
        "    a[:,0:shift[0]] = 0\n",
        "  else:\n",
        "    a[:,image_size_orig+shift[0]:] = 0\n",
        "  a = np.roll(a, shift[1], axis = 0)\n",
        "  if(shift[1] >= 0):\n",
        "    a[0:shift[1],:] = 0\n",
        "  else:\n",
        "    a[image_size_orig+shift[1]:,:] = 0\n",
        "  return a\n",
        "\n",
        "\n",
        "def init_data_gen():\n",
        "  global nb_train_2012, nb_train_2007, nb_test_2007, orig_nb_images, nb_class\n",
        "  global nb_images_per_batch, nb_keep_val, nb_obj_val, image_size, image_size_orig\n",
        "  global rot_amp, contrast_amp, flip_hor, flip_vert, shift_amp_w, shift_amp_h, zoom_prop\n",
        "  global input_data, targets, input_val, targets_val, all_im, all_im_prop\n",
        "\n",
        "  nb_train_2012 = 11540\n",
        "  nb_train_2007 = 5011\n",
        "  nb_test_2007 = 4952\n",
        "  orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "  nb_keep_val = 1000 #keep in 2012 trainval\n",
        "  nb_obj_val = 2870\n",
        "\n",
        "  nb_class = 20\n",
        "  image_size_orig = 224\n",
        "  image_size = 96\n",
        "  nb_images_per_batch = 4000\n",
        "\n",
        "  rot_amp = 0.0 #in deg, not yet in use\n",
        "  contrast_amp = 0.0 #in percent\n",
        "  flip_hor = 0.5 #total proportion\n",
        "  flip_vert = 0.0 #total proportion\n",
        "  shift_amp_w = 0.2 #percent of image_size\n",
        "  shift_amp_h = 0.2 #percent of image_size\n",
        "  zoom_prop = 0.2 #percent of image_size\n",
        "\n",
        "  all_im = np.fromfile(\"/content/IRMIA_2022/dataset/all_im.dat\", dtype=\"uint8\")\n",
        "  all_im_prop = np.fromfile(\"/content/IRMIA_2022/dataset/all_im_prop.dat\", dtype=\"float32\")\n",
        "  all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "  all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "  input_data = np.zeros((nb_images_per_batch,image_size*image_size*3), dtype=\"float32\")\n",
        "  targets = np.zeros((nb_images_per_batch,nb_class), dtype=\"float32\")\n",
        "\n",
        "  input_val = np.zeros((nb_obj_val,image_size*image_size*3), dtype=\"float32\")\n",
        "  targets_val = np.zeros((nb_obj_val,nb_class), dtype=\"float32\")\n",
        "\n",
        "\n",
        "def create_train_batch(visual):\n",
        "  visual_iter = 0\n",
        "  for i in range(0, nb_images_per_batch):\n",
        "    \n",
        "    i_d = np.random.randint(0,orig_nb_images - nb_keep_val)\n",
        "    \n",
        "    if(i_d < nb_train_2007):\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d]+\".xml\")\n",
        "    elif(i_d < nb_train_2007+nb_test_2007):\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2007]+\".xml\")\n",
        "    else:\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d - nb_train_2007 - nb_test_2007]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    patch = np.copy(all_im[i_d])\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "    im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "    obj_id = np.random.randint(0,len(im_obj_list))\n",
        "    k = 0\n",
        "    for obj in im_obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      if(obj_id == k):\n",
        "        break\n",
        "      else:\n",
        "        k += 1\n",
        "    \n",
        "    oclass = obj.find(\"name\", namespaces=None)\n",
        "    int_class = np.where(class_list[:] == oclass.text)[0]\n",
        "    l_targ = np.zeros(nb_class)\n",
        "    l_targ[int_class] = 1\n",
        "    targets[i,:] = np.copy(l_targ)\n",
        "\n",
        "    bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "    \n",
        "    xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "    ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "    xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "    ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "    \n",
        "    width = (xmax-xmin); height = (ymax-ymin)\n",
        "    \n",
        "    zoom_val = np.random.random()*zoom_prop + 0.1\n",
        "    \n",
        "    xmin -= int(zoom_val*width)\n",
        "    xmax += int(zoom_val*width)\n",
        "    ymin -= int(zoom_val*height)\n",
        "    ymax += int(zoom_val*height)\n",
        "    \n",
        "    shift_w_val = (np.random.random()*2.0 - 1.0)*shift_amp_w\n",
        "    shift_h_val = (np.random.random()*2.0 - 1.0)*shift_amp_h\n",
        "\n",
        "    width = (xmax-xmin); height = (ymax-ymin)\n",
        "    \n",
        "    patch = roll_zeropad(patch, np.array([int(shift_w_val*width),int(shift_h_val*height)]))\n",
        "\n",
        "    im = Image.fromarray(patch)\n",
        "    max_size = max((xmax-xmin),(ymax-ymin))\n",
        "    c_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "    xmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "    ymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "    \n",
        "    im_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "    im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "    \n",
        "    im_array = np.asarray(im_loc)\n",
        "    \n",
        "    flip_w = 0\n",
        "    flip_h = 0\n",
        "    if(np.random.random() < flip_hor):\n",
        "      flip_w = 1\n",
        "      im_array = np.flip(im_array, axis=1)\n",
        "    if(np.random.random() < flip_vert):\n",
        "      flip_h = 1\n",
        "      im_array = np.flip(im_array, axis=0)\n",
        "    \n",
        "    if(visual > 0):\n",
        "      print(class_list_short[int_class])\n",
        "      plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "      plt.imshow(im_array)\n",
        "      plt.show()\n",
        "      visual_iter += 1\n",
        "      if(visual_iter >= visual):\n",
        "        return\n",
        "    \n",
        "    for depth in range(0,3):\n",
        "      input_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "    \n",
        "  return input_data, targets\n",
        "\n",
        "\n",
        "def create_val_batch(visual):\n",
        "  visual_iter = 0\n",
        "\n",
        "  k = 0\n",
        "  for i in range(0, nb_keep_val):\n",
        "        \n",
        "    tree = ET.parse(\"../dataset/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[nb_train_2012 - nb_keep_val + i]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    patch = np.copy(all_im[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i])\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i]\n",
        "\n",
        "    im = Image.fromarray(patch)\n",
        "\n",
        "    im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "    for obj in im_obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      \n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      int_class = np.where(class_list[:] == oclass.text)[0]\n",
        "      l_targ = np.zeros(nb_class)\n",
        "      l_targ[int_class] = 1\n",
        "      targets_val[k,:] = np.copy(l_targ)\n",
        "\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "    \n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "    \n",
        "      width = (xmax-xmin); height = (ymax-ymin)\n",
        "\n",
        "      zoom_val = 0.1\n",
        "\n",
        "      xmin -= int(zoom_val*width)\n",
        "      xmax += int(zoom_val*width)\n",
        "      ymin -= int(zoom_val*height)\n",
        "      ymax += int(zoom_val*height)\n",
        "\n",
        "      max_size = max((xmax-xmin),(ymax-ymin))\n",
        "      c_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "      xmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "      ymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "    \n",
        "      im_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "      im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "    \n",
        "      im_array = np.asarray(im_loc)\n",
        "    \n",
        "      if(visual > 0):\n",
        "        print(class_list_short[int_class])\n",
        "        plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "        plt.imshow(im_array)\n",
        "        plt.show()\n",
        "        visual_iter += 1\n",
        "        if(visual_iter >= visual):\n",
        "          return\n",
        "    \n",
        "      for depth in range(0,3):\n",
        "        input_val[k,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "      k+=1\n",
        "    \n",
        "  return input_val, targets_val\n",
        "\n"
      ],
      "metadata": {
        "id": "1Mp7fVUBE30T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training image examples"
      ],
      "metadata": {
        "id": "s1PVa19yEjMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/classifier/test_gen.py\n",
        "\n",
        "import data_gen as gn\n",
        "\n",
        "gn.init_data_gen()\n",
        "\n",
        "gn.create_train_batch(10)\n",
        "\n",
        "#gn.create_val_batch(5)\n"
      ],
      "metadata": {
        "id": "Bzv7yFvG1ajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#might need to reload the notebook execution environment for changes to unload previous data_gen\n",
        "%cd /content/IRMIA_2022/classifier/\n",
        "\n",
        "%run test_gen.py\n"
      ],
      "metadata": {
        "id": "r-U9dkltuqih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\.Training the classifier\n"
      ],
      "metadata": {
        "id": "dFlwUL7eE6Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/classifier/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64')\n",
        "import CIANNA as cnn\n",
        "import data_gen as gn\n",
        "\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "\tload_epoch = int(sys.argv[1])\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\t\n",
        "gn.init_data_gen()\t\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = gn.create_train_batch(0)\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images_per_batch, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 1000 #keep in 2012 trainval\n",
        "nb_obj_val = 2870\n",
        "nb_class = 20\n",
        "\n",
        "nb_images_per_batch = 4000\n",
        "image_size = 96\n",
        "\n",
        "\n",
        "\n",
        "cnn.init(in_dim=np.array([image_size,image_size]),in_nb_ch=3, out_dim=nb_class, b_size=16, \n",
        "\t\tcomp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "\n",
        "input_data, targets = gn.create_train_batch(0)\n",
        "input_val, targets_val = gn.create_val_batch(0)\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_batch, input_data[:,:], targets[:,:])\n",
        "cnn.create_dataset(\"VALID\", nb_obj_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "load_epoch = 0\n",
        "if(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "\t#Switch to bottom line to load pre-trained network\n",
        "\t#cnn.load(\"/content/IRMIA_2022/pre_trained_nets/classifier_net0_s1100.dat\",1000, bin=1)\n",
        "\n",
        "else:\n",
        "\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=48, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=96, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=256, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=512, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=512, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.dense(nb_neurons=1024, activation=\"RELU\", drop_rate=0.4)\n",
        "\tcnn.dense(nb_neurons=512, activation=\"RELU\")\n",
        "\tcnn.dense(nb_neurons=nb_class, activation=\"SMAX\")\n",
        "\n",
        "\n",
        "for block in range(0,1000):\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\t\n",
        "\tcnn.train(nb_epoch=2, learning_rate=0.004, end_learning_rate=0.0004, \n",
        "\t\t\t\tdecay=0.003, momentum=0.7, shuffle_every=0, confmat=1, \n",
        "\t\t\t\tcontrol_interv=10, save_every=100, silent=1, TC_scale_factor=16.0, save_bin=1)\n",
        "\t\n",
        "\tif(block == 0):\n",
        "\t\tcnn.perf_eval()\n",
        "\t\n",
        "\tt.join()\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "hqz7tMvoz5mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "os4SbssRhBA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B - Sliding window detector"
      ],
      "metadata": {
        "id": "R1hzOMVAFExp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\\. Train and valid data generation\n"
      ],
      "metadata": {
        "id": "W-aEcbXVFQGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "mkdir sliding_window\n",
        "cd sliding_window"
      ],
      "metadata": {
        "id": "A9n1JmnmFkHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding a \"background class\" to the data generator"
      ],
      "metadata": {
        "id": "NyKOs6O4F9gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/sliding_window/data_gen.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"../dataset/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"../dataset/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"../dataset/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "\n",
        "def make_square(im, min_size, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    size = max(min_size, x, y)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "def roll_zeropad(a, shift):\n",
        "  a = np.roll(a, shift[0], axis = 1)\n",
        "  if(shift[0] >= 0):\n",
        "    a[:,0:shift[0]] = 0\n",
        "  else:\n",
        "    a[:,image_size_orig+shift[0]:] = 0\n",
        "  a = np.roll(a, shift[1], axis = 0)\n",
        "  if(shift[1] >= 0):\n",
        "    a[0:shift[1],:] = 0\n",
        "  else:\n",
        "    a[image_size_orig+shift[1]:,:] = 0\n",
        "  return a\n",
        "\t\n",
        "def fct_inter(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\n",
        "\treturn float(inter_2d)\n",
        "\n",
        "\n",
        "def init_data_gen():\n",
        "  global nb_train_2012, nb_train_2007, nb_test_2007, orig_nb_images, nb_class\n",
        "  global nb_images_per_batch, nb_keep_val, nb_empty_val, nb_obj_val, image_size, image_size_orig\n",
        "  global rot_amp, contrast_amp, flip_hor, flip_vert, shift_amp_w, shift_amp_h, zoom_prop\n",
        "  global input_data, targets, input_val, targets_val, all_im, all_im_prop\n",
        "\n",
        "  nb_train_2012 = 11540\n",
        "  nb_train_2007 = 5011\n",
        "  nb_test_2007 = 4952\n",
        "  orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "  nb_keep_val = 1000 #keep in 2012 trainval\n",
        "  nb_obj_val = 2870\n",
        "  nb_empty_val = 500\n",
        "\n",
        "  nb_class = 20\n",
        "  image_size_orig = 224\n",
        "  image_size = 96\n",
        "  nb_images_per_batch = 4000\n",
        "\n",
        "  rot_amp = 0.0 #in deg, not yet in use\n",
        "  contrast_amp = 0.0 #in percent\n",
        "  flip_hor = 0.5 #total proportion\n",
        "  flip_vert = 0.0 #total proportion\n",
        "  shift_amp_w = 0.2 #percent of image_size\n",
        "  shift_amp_h = 0.2 #percent of image_size\n",
        "  zoom_prop = 0.2 #percent of image_size\n",
        "\n",
        "  all_im = np.fromfile(\"/content/IRMIA_2022/dataset/all_im.dat\", dtype=\"uint8\")\n",
        "  all_im_prop = np.fromfile(\"/content/IRMIA_2022/dataset/all_im_prop.dat\", dtype=\"float32\")\n",
        "  all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "  all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "  input_data = np.zeros((nb_images_per_batch,image_size*image_size*3), dtype=\"float32\")\n",
        "  targets = np.zeros((nb_images_per_batch,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "  input_val = np.zeros((nb_obj_val+nb_empty_val,image_size*image_size*3), dtype=\"float32\")\n",
        "  targets_val = np.zeros((nb_obj_val+nb_empty_val,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "\n",
        "def create_train_batch(visual):\n",
        "  visual_iter = 0\n",
        "\n",
        "  for i in range(0, nb_images_per_batch):\n",
        "    \n",
        "    i_d = np.random.randint(0,orig_nb_images - nb_keep_val)\n",
        "    \n",
        "    if(i_d < nb_train_2007):\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d]+\".xml\")\n",
        "    elif(i_d < nb_train_2007+nb_test_2007):\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2007]+\".xml\")\n",
        "    else:\n",
        "      tree = ET.parse(\"../dataset/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d - nb_train_2007 - nb_test_2007]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    patch = np.copy(all_im[i_d])\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "    if(np.random.random() > 0.2):\n",
        "      \n",
        "      im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "      obj_id = np.random.randint(0,len(im_obj_list))\n",
        "      k = 0\n",
        "      for obj in im_obj_list:\n",
        "        diff = obj.find(\"difficult\", namespaces=None)\n",
        "        if(diff.text == \"1\"):\n",
        "          continue\n",
        "        if(obj_id == k):\n",
        "          break\n",
        "        else:\n",
        "          k += 1\n",
        "      \n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      int_class = int(np.where(class_list[:-1] == oclass.text)[0])\n",
        "      l_targ = np.zeros(nb_class+1)\n",
        "      l_targ[int_class] = 1\n",
        "      targets[i,:] = np.copy(l_targ)\n",
        "\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "      \n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "      \n",
        "      width = (xmax-xmin); height = (ymax-ymin)\n",
        "      \n",
        "      zoom_val = np.random.random()*zoom_prop + 0.1\n",
        "      \n",
        "      xmin -= int(zoom_val*width)\n",
        "      xmax += int(zoom_val*width)\n",
        "      ymin -= int(zoom_val*height)\n",
        "      ymax += int(zoom_val*height)\n",
        "      \n",
        "      shift_w_val = (np.random.random()*2.0 - 1.0)*shift_amp_w\n",
        "      shift_h_val = (np.random.random()*2.0 - 1.0)*shift_amp_h\n",
        "      \n",
        "      width = (xmax-xmin); height = (ymax-ymin)\n",
        "\n",
        "      patch = roll_zeropad(patch, np.array([int(shift_w_val*width),int(shift_h_val*height)]))\n",
        "      \n",
        "      im = Image.fromarray(patch)\n",
        "\n",
        "      max_size = max((xmax-xmin),(ymax-ymin))\n",
        "      c_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "      xmin = int(c_x - 0.5*max_size); xmax = int(c_x + 0.5*max_size)\n",
        "      ymin = int(c_y - 0.5*max_size); ymax = int(c_y + 0.5*max_size)\n",
        "      \n",
        "      im_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "      im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "      \n",
        "      im_array = np.asarray(im_loc)\n",
        "      \n",
        "      flip_w = 0\n",
        "      flip_h = 0\n",
        "      if(np.random.random() < flip_hor):\n",
        "        flip_w = 1\n",
        "        im_array = np.flip(im_array, axis=1)\n",
        "      if(np.random.random() < flip_vert):\n",
        "        flip_h = 1\n",
        "        im_array = np.flip(im_array, axis=0)\n",
        "      \n",
        "      if(visual > 0):\n",
        "        print(class_list_short[int_class])\n",
        "        plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "        plt.imshow(im_array)\n",
        "        plt.show()\n",
        "        visual_iter += 1\n",
        "        if(visual_iter >= visual):\n",
        "          return\n",
        "\n",
        "      for depth in range(0,3):\n",
        "        input_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "    \n",
        "    else:\n",
        "      found = 0\n",
        "      l_size = 160\n",
        "      try_per_size = 10\n",
        "\n",
        "      int_class = 20\n",
        "      l_targ = np.zeros(nb_class+1)\n",
        "      l_targ[nb_class] = 1\n",
        "      targets[i,:] = np.copy(l_targ)\n",
        "      \n",
        "      im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "      box_list = np.zeros((len(im_obj_list),4))\n",
        "      k = 0\n",
        "      for obj in im_obj_list:\n",
        "        diff = obj.find(\"difficult\", namespaces=None)\n",
        "        if(diff.text == \"1\"):\n",
        "          continue\n",
        "        \n",
        "        bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "        \n",
        "        xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "        ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "        xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "        ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "        box_list[k,:] = np.array([xmin,ymin,xmax,ymax])\n",
        "        k += 1\n",
        "      \n",
        "      count_per_size = 0\n",
        "      while((not found) and (l_size >= 0)):\n",
        "        size = l_size + 32\n",
        "        \n",
        "        c_x = np.random.random()*(image_size_orig - size) + size/2\n",
        "        c_y = np.random.random()*(image_size_orig - size) + size/2\n",
        "        \n",
        "        xmin = int(c_x - 0.5*size); xmax = int(c_x + 0.5*size)\n",
        "        ymin = int(c_y - 0.5*size); ymax = int(c_y + 0.5*size)\n",
        "        \n",
        "        c_box = np.array([xmin, ymin, xmax, ymax])\n",
        "        \n",
        "        im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "        inter_count = 0\n",
        "        for l in range(0,len(im_obj_list)):\n",
        "          loc_inter = fct_inter(c_box, box_list[l,:])\n",
        "          if(loc_inter > 0.0):\n",
        "            inter_count += 1\n",
        "        \n",
        "        if(inter_count == 0):\n",
        "          found = 1\n",
        "        \n",
        "        count_per_size += 1\n",
        "        if(count_per_size >= try_per_size):\n",
        "          count_per_size = 0\n",
        "          l_size -= 32\n",
        "      \n",
        "      if(not found):\n",
        "        im_array = np.zeros((image_size,image_size,3))\n",
        "        \n",
        "      else:\n",
        "        \n",
        "        im = Image.fromarray(patch)\n",
        "      \n",
        "        im_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "        im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "        \n",
        "        im_array = np.asarray(im_loc)\n",
        "        \n",
        "        flip_w = 0\n",
        "        flip_h = 0\n",
        "        if(np.random.random() < flip_hor):\n",
        "          flip_w = 1\n",
        "          im_array = np.flip(im_array, axis=1)\n",
        "        if(np.random.random() < flip_vert):\n",
        "          flip_h = 1\n",
        "          im_array = np.flip(im_array, axis=0)\n",
        "      \n",
        "      if(visual > 0):\n",
        "        print(class_list_short[int_class])\n",
        "        plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "        plt.imshow(im_array)\n",
        "        plt.show()\n",
        "        visual_iter += 1\n",
        "        if(visual_iter >= visual):\n",
        "          return\n",
        "          \n",
        "      for depth in range(0,3):\n",
        "        input_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\n",
        "  return input_data, targets\n",
        "\n",
        "def create_val_batch(visual):\n",
        "  visual_iter = 0\n",
        "\n",
        "  loc = 0\n",
        "  for i in range(0, nb_keep_val):\n",
        "    \n",
        "    patch = np.copy(all_im[orig_nb_images-nb_keep_val+i])\n",
        "\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images-nb_keep_val+i]\n",
        "\n",
        "    tree = ET.parse(\"../dataset/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[nb_train_2012-nb_keep_val+i]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    im = Image.fromarray(patch)\n",
        "    \n",
        "    im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "    for obj in im_obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      \n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      int_class = int(np.where(class_list[:-1] == oclass.text)[0])\n",
        "      l_targ = np.zeros(nb_class+1)\n",
        "      l_targ[int_class] = 1\n",
        "      targets_val[loc,:] = np.copy(l_targ)\n",
        "\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "    \n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "      \n",
        "      width = (xmax-xmin); height = (ymax-ymin)\n",
        "      \n",
        "      zoom_val = 0.1\n",
        "      \n",
        "      xmin -= int(zoom_val*width)\n",
        "      xmax += int(zoom_val*width)\n",
        "      ymin -= int(zoom_val*height)\n",
        "      ymax += int(zoom_val*height)\n",
        "      \n",
        "      max_size = max((xmax-xmin),(ymax-ymin))\n",
        "      c_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "      xmin = c_x - 0.5*max_size; xmax = c_x + 0.5*max_size\n",
        "      ymin = c_y - 0.5*max_size; ymax = c_y + 0.5*max_size \n",
        "      \n",
        "      im_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "      im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "      im_array = np.asarray(im_loc)\n",
        "\n",
        "      if(False and visual > 0):\n",
        "        print(class_list_short[int_class])\n",
        "        plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "        plt.imshow(im_array)\n",
        "        plt.show()\n",
        "        visual_iter += 1\n",
        "        if(visual_iter >= visual):\n",
        "          return\n",
        "\n",
        "      for depth in range(0,3):\n",
        "        input_val[loc,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "      \n",
        "      loc += 1\n",
        "\n",
        "  for i in range(0, nb_empty_val):\n",
        "    \n",
        "    i_d = np.random.randint(0,nb_keep_val)\n",
        "    \n",
        "    patch = np.copy(all_im[orig_nb_images-nb_keep_val+i_d])\n",
        "\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images-nb_keep_val+i_d]\n",
        "\n",
        "    tree = ET.parse(\"../dataset/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[nb_train_2012-nb_keep_val+i_d]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    im = Image.fromarray(patch)\n",
        "    \n",
        "    found = 0\n",
        "    l_size = 160\n",
        "    try_per_size = 10\n",
        "    \n",
        "    int_class = 20\n",
        "    l_targ = np.zeros(nb_class+1)\n",
        "    l_targ[nb_class] = 1\n",
        "    targets_val[loc+i,:] = np.copy(l_targ)\n",
        "    \n",
        "    im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "    box_list = np.zeros((len(im_obj_list),4))\n",
        "    k = 0\n",
        "    for obj in im_obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      \n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "      \n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "      box_list[k,:] = np.array([xmin,ymin,xmax,ymax])\n",
        "      k += 1\n",
        "    \n",
        "    count_per_size = 0\n",
        "    while((not found) and (l_size >= 0)):\n",
        "      size = l_size + 32\n",
        "      \n",
        "      c_x = np.random.random()*(image_size_orig - size) + size/2\n",
        "      c_y = np.random.random()*(image_size_orig - size) + size/2\n",
        "      \n",
        "      xmin = int(c_x - 0.5*size); xmax = int(c_x + 0.5*size)\n",
        "      ymin = int(c_y - 0.5*size); ymax = int(c_y + 0.5*size)\n",
        "      \n",
        "      c_box = np.array([xmin, ymin, xmax, ymax])\n",
        "      \n",
        "      im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "      inter_count = 0\n",
        "      for l in range(0,len(im_obj_list)):\n",
        "        loc_inter = fct_inter(c_box, box_list[l,:])\n",
        "        if(loc_inter > 0.0):\n",
        "          inter_count += 1\n",
        "      \n",
        "      if(inter_count == 0):\n",
        "        found = 1\n",
        "      \n",
        "      count_per_size += 1\n",
        "      if(count_per_size >= try_per_size):\n",
        "        count_per_size = 0\n",
        "        l_size -= 32\n",
        "    \n",
        "    if(not found):\n",
        "      im_array = np.zeros((image_size,image_size,3))\n",
        "      \n",
        "    else:\n",
        "      \n",
        "      im = Image.fromarray(patch)\n",
        "    \n",
        "      im_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "      im_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "      \n",
        "      im_array = np.asarray(im_loc)\n",
        "      \n",
        "      flip_w = 0\n",
        "      flip_h = 0\n",
        "      if(np.random.random() < flip_hor):\n",
        "        flip_w = 1\n",
        "        im_array = np.flip(im_array, axis=1)\n",
        "      if(np.random.random() < flip_vert):\n",
        "        flip_h = 1\n",
        "        im_array = np.flip(im_array, axis=0)\n",
        "    \n",
        "    if(visual > 0):\n",
        "        print(class_list_short[int_class])\n",
        "        plt.subplots(figsize=(4,4), dpi=100, constrained_layout=True)\n",
        "        plt.imshow(im_array)\n",
        "        plt.show()\n",
        "        visual_iter += 1\n",
        "        if(visual_iter >= visual):\n",
        "          return\n",
        "\n",
        "    for depth in range(0,3):\n",
        "      input_val[loc+i,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\n",
        "  return input_val, targets_val\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bzi-xvGGF1RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training image examples"
      ],
      "metadata": {
        "id": "5PQlbbsSMQIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/sliding_window/test_gen.py\n",
        "\n",
        "import data_gen as gn\n",
        "\n",
        "gn.init_data_gen()\n",
        "\n",
        "gn.create_train_batch(10)\n",
        "\n",
        "gn.create_val_batch(0)\n"
      ],
      "metadata": {
        "id": "8iP12KrPMQ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#might need to reload the notebook execution environment for changes to unload previous data_gen\n",
        "%cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "%run test_gen.py"
      ],
      "metadata": {
        "id": "zQ7PdsfBMnha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\.Training the detection classifier"
      ],
      "metadata": {
        "id": "B58RU8bBS-mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64')\n",
        "import CIANNA as cnn\n",
        "import data_gen as gn\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "  load_epoch = int(sys.argv[1])\n",
        "\n",
        "def i_ar(int_list):\n",
        "  return np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "  return np.array(float_list, dtype=\"float32\")\n",
        "\t\n",
        "gn.init_data_gen()\t\n",
        "\n",
        "def data_augm():\n",
        "  input_data, targets = gn.create_train_batch(0)\n",
        "  cnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "  cnn.create_dataset(\"TRAIN_buf\", nb_images_per_batch, input_data[:,:], targets[:,:], silent=1)\n",
        "  return\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 1000\n",
        "nb_empty_val = 500\n",
        "total_nb_obj_images_val = 2870 + nb_empty_val #From data_gen execution, linked to keep_val\n",
        "nb_class = 20\n",
        "\n",
        "nb_images_per_batch = 4000\n",
        "image_size = 96\n",
        "\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]),in_nb_ch=3, out_dim=nb_class+1, b_size=16, \n",
        "\t\tcomp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "input_data, targets = gn.create_train_batch(0)\n",
        "input_val, targets_val = gn.create_val_batch(0)\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_batch, input_data[:,:], targets[:,:])\n",
        "cnn.create_dataset(\"VALID\", total_nb_obj_images_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "load_epoch = 0\n",
        "if(load_epoch > 0):\n",
        "  cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "  #Switch to bottom line to load pre-trained network\n",
        "\t#cnn.load(\"/content/IRMIA_2022/pre_trained_nets/sliding_window_net0_s1200.dat\",1200, bin=1)\n",
        "else:\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=48, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=96, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=256, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=512, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.conv(f_size=i_ar([3,3]), nb_filters=512, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "  cnn.dense(nb_neurons=1024, activation=\"RELU\", drop_rate=0.4)\n",
        "  cnn.dense(nb_neurons=512, activation=\"RELU\")\n",
        "  cnn.dense(nb_neurons=nb_class+1, activation=\"SMAX\")\n",
        "\n",
        "for block in range(0,500):\n",
        "  t = Thread(target=data_augm)\n",
        "  t.start()\n",
        "\n",
        "  cnn.train(nb_epoch=2, learning_rate=0.004, end_learning_rate=0.0004, \n",
        "      decay=0.003, momentum=0.7, shuffle_every=0, confmat=1, \n",
        "      control_interv=10, save_every=100, silent=1, TC_scale_factor=16.0,save_bin=1)\n",
        "\n",
        "  if(block == 0):\n",
        "    cnn.perf_eval()\n",
        "\n",
        "  t.join()\n",
        "  cnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "EGaf2q77TGR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3\\. Sliding window prediction"
      ],
      "metadata": {
        "id": "ZuU0yjzCnNar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regions definition and network inference"
      ],
      "metadata": {
        "id": "X9LpPb72qd_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import re\n",
        "import os\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64')\n",
        "import CIANNA as cnn\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "\tload_epoch = int(sys.argv[1])\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\\\n",
        "      \"bus\",\"car\", \"cat\",\"chair\",\"cow\",\\\n",
        "      \"diningtable\",\"dog\",\"horse\", \"motorbike\",\"person\",\\\n",
        "      \"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\\\n",
        "      \"bus\",\"car\",\"cat\",\"chair\",\"cow\",\\\n",
        "      \"table\",\"dog\",\"horse\", \"m-bike\",\"person\",\\\n",
        "      \"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"../dataset/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 200 #not enough memory in notebook for the 1000 values\n",
        "nb_keep_val_orig = 1000\n",
        "nb_class = 20\n",
        "\n",
        "image_size_orig = 224\n",
        "image_size = 96\n",
        "\n",
        "frac_size = np.array([224,112,56])\n",
        "frac_stride = np.array([0,56,28])\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/dataset/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/dataset/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "nb_regions_per_im = 1\n",
        "for l in range(1,np.size(frac_size)):\n",
        "\tnb_regions_per_im += ((image_size_orig-frac_size[l])/frac_stride[l] + 1)**2\n",
        "\n",
        "print (nb_regions_per_im)\n",
        "all_nb_test_images = int(nb_regions_per_im*nb_keep_val)\n",
        "\n",
        "print (all_nb_test_images)\n",
        "\n",
        "input_test = np.zeros((all_nb_test_images,image_size*image_size*3), dtype=\"float32\")\n",
        "targets_test = np.zeros((all_nb_test_images,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "k = 0\n",
        "for i in tqdm(range(0, nb_keep_val)):\n",
        "\t\n",
        "\ti_d = orig_nb_images - nb_keep_val_orig + i\n",
        "\t\n",
        "\tpatch = np.copy(all_im[i_d])\n",
        "\t\n",
        "\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\t\n",
        "\tim = Image.fromarray(patch)\n",
        "\t\n",
        "\tfor l in range(0, np.size(frac_size)):\n",
        "\t\t\n",
        "\t\tif(l == 0):\n",
        "\t\t\tnb_reg = 1\n",
        "\t\telse:\n",
        "\t\t\tnb_reg = int((image_size_orig-frac_size[l])/frac_stride[l] + 1)\n",
        "\t\t\n",
        "\t\tfor l_x in range(0, nb_reg):\n",
        "\t\t\tfor l_y in range(0, nb_reg):\n",
        "\t\t\t\t\n",
        "\t\t\t\txmin = l_x * frac_stride[l]\n",
        "\t\t\t\tymin = l_y * frac_stride[l]\n",
        "\t\t\t\txmax = xmin + frac_size[l]\n",
        "\t\t\t\tymax = ymin + frac_size[l]\n",
        "\t\t\t\t\n",
        "\t\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "\t\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\t\t\n",
        "\t\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\t\t\n",
        "\t\t\t\tfor depth in range(0,3):\n",
        "\t\t\t\t\tinput_test[k,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\t\tk += 1\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]),in_nb_ch=3, out_dim=nb_class+1, b_size=20, \n",
        "\t\tcomp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "cnn.create_dataset(\"TEST\", all_nb_test_images, input_test[:,:], targets_test[:,:])\n",
        "\n",
        "load_epoch = 1200\n",
        "if(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "\t#Switch to bottom line to load pre-trained network\n",
        "\t#cnn.load(\"/content/IRMIA_2022/pre_trained_nets/sliding_window_net0_s1200.dat\",1200, bin=1)\n",
        "else:\n",
        "\tfiles = os.listdir(\"net_save/\")\n",
        "\tpaths = [os.path.join(\"net_save/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent save : \" + path)\n",
        "\t\n",
        "\tcnn.load(path, r_load_epoch[0], bin=1)\n",
        "\t\n",
        "cnn.forward(no_error=1)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "FCTCRmmqnN7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction vizualisation"
      ],
      "metadata": {
        "id": "Wct5u9N6qmQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import re\n",
        "import bisect\n",
        "import os\n",
        "\n",
        "import sys\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"../dataset/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 200 #not enough memory in notebook for the 1000 values\n",
        "nb_keep_val_orig = 1000\n",
        "nb_class = 20\n",
        "\n",
        "image_size_orig = 224\n",
        "image_size = 96\n",
        "\n",
        "frac_size = np.array([224,112,56])\n",
        "frac_stride = np.array([0,56,28])\n",
        "nb_reg_per_frac = np.array([1,0,0])\n",
        "cumul_nb_per_frac = np.array([1,0,0])\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/dataset/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/dataset/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "nb_regions_per_im = 1\n",
        "for l in range(1,np.size(frac_size)):\n",
        "\tnb_reg_per_frac[l] = ((image_size_orig-frac_size[l])/frac_stride[l] + 1)\n",
        "\tnb_regions_per_im += nb_reg_per_frac[l]**2\n",
        "\tcumul_nb_per_frac[l] = nb_regions_per_im\n",
        "\n",
        "print (nb_reg_per_frac, cumul_nb_per_frac)\n",
        "\n",
        "load_epoch = 0\n",
        "if(load_epoch == 0):\n",
        "\tfiles = os.listdir(\"fwd_res/\")\n",
        "\tpaths = [os.path.join(\"fwd_res/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[_s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent prediction : \" + path)\n",
        "\t\n",
        "\tload_epoch = r_load_epoch[0]\n",
        "\n",
        "\n",
        "pred_raw = np.loadtxt(\"fwd_res/net0_%04d.dat\"%load_epoch)\n",
        "\n",
        "pred_data = np.reshape(pred_raw,(nb_keep_val, int(nb_regions_per_im), 22))\n",
        "\n",
        "\n",
        "width_list = [2.0, 1.5, 1.0]\n",
        "\n",
        "i_d = 32\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(6,12), dpi=210, constrained_layout=True)\n",
        "\n",
        "for l_h in range(0, nb_h):\n",
        "  for l_w in range(0, nb_w):\n",
        "    loc = i_d + l_w + l_h*nb_w\n",
        "    patch = np.copy(all_im[orig_nb_images - nb_keep_val_orig + loc])\n",
        "    \n",
        "    ax[l_h,l_w].imshow(patch)\n",
        "    ax[l_h,l_w].axis('off')\n",
        "\n",
        "    for l in range(0,int(nb_regions_per_im)):\n",
        "      max_loc = np.argmax(pred_data[loc,l,:])\n",
        "      max_val = np.max(pred_data[loc,l,:])\n",
        "      if(max_val > 0.8 and max_loc < nb_class):\n",
        "        \n",
        "        index = bisect.bisect(cumul_nb_per_frac, l)\n",
        "        \n",
        "        if(l > 0):\n",
        "          i_l = l - cumul_nb_per_frac[index-1]\n",
        "        else:\n",
        "          i_l = 0\n",
        "        i_x = i_l // nb_reg_per_frac[index]\n",
        "        i_y = i_l % nb_reg_per_frac[index]\n",
        "        \n",
        "        xmin = i_x * frac_stride[index] - 0.5 + 2*index; ymin = i_y * frac_stride[index] - 0.5 + 2*index\n",
        "        xmax = xmin + frac_size[index] - 4*index; ymax = ymin + frac_size[index] - 4*index\n",
        "        el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth= width_list[index], fill=False, color=plt.cm.tab20(max_loc), zorder=3)\n",
        "        ax[l_h,l_w].add_patch(el)\n",
        "        ax[l_h,l_w].text(xmin+3, ymin+14, \"%s-%0.2f\"%(class_list_short[max_loc], max_val), c=plt.cm.tab20(max_loc), fontsize=6, clip_on=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HfToMT80qbuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X8qLlpnVhDzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C - The YOLO object detector\n",
        "(YOLO - You Only Look Once)"
      ],
      "metadata": {
        "id": "RLtKgGx6stfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\\. Train and valid data generation"
      ],
      "metadata": {
        "id": "ssyMWqWr2PWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic Image augmentation and bounding box targets"
      ],
      "metadata": {
        "id": "Ydmkorgw2XUK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kX12wMn62mwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}