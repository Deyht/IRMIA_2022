{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DL IRMIA summer school : Object Detection with YOLO**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/IRMIA_2022/blob/main/IRMIA_DL_Summer_school_2022_Object_Detection_with_YOLO_full_v2.ipynb)"
      ],
      "metadata": {
        "id": "0ZqgJPXRWFgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction - Notebook Setup**\n",
        "\n",
        "**Important notes**:   \n",
        "1) Due to RAM limits on the free Colab version, the notebook kernel might crash at some points if running it all at once or if re-running specific cells multiple times. A simple restart of the runtime kernel (Runtime -> Restart runtime) will solve the issue without losing the locally saved files (datasets, network saves, framework, etc.). Then simply re-run from the group of cells that crashed.\n",
        "\n",
        "Each **independent** part of the notebook has been verified to run on the free version of Colab.\n",
        "\n",
        "2) The Introduction part, which includes dataset download/formatting and the CIANNA framework installation, must be run every time the runtime is fully shut down and disconnected, as it is used in all parts A, B, and C.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the slides accompanying the notebook**  \n",
        "https://github.com/Deyht/IRMIA_2022/blob/main/DL_obj_detetion_with_YOLO_slides_full_v2.pdf\n"
      ],
      "metadata": {
        "id": "uz7N4sQtedH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"repo_cloning\"></a>\n",
        "### **1\\. Clone the associated Git repository**"
      ],
      "metadata": {
        "id": "6GSYAKkTd7Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/Deyht/IRMIA_2022\n",
        "\n",
        "cd /content/IRMIA_2022/pre_trained_nets/\n",
        "tar -xvzf pre_trained_nets_v2.tar.gz\n"
      ],
      "metadata": {
        "id": "rW8gwTyHd7zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"data_download\"></a>\n",
        "### **2\\. PASCAL VOC 2012 and 2007**\n",
        "\n"
      ],
      "metadata": {
        "id": "cKGTBYPxdS-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Dataset download\n"
      ],
      "metadata": {
        "id": "9NqfAfh7FLdc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "704uuUNvZ43G"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "cd IRMIA_2022/\n",
        "\n",
        "mkdir datasets\n",
        "cd datasets\n",
        "\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "tar -xf VOCtrainval_11-May-2012.tar\n",
        "tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "tar -xf VOCtest_06-Nov-2007.tar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"data_format\"></a>\n",
        "#### Format dataset"
      ],
      "metadata": {
        "id": "AK_pxCkv2i9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/datasets/\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "def make_square(im, min_size, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    size = max(min_size, x, y)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 4952\n",
        "image_size = 288\n",
        "nb_class = 20\n",
        "\n",
        "all_im = np.zeros((orig_nb_images, image_size, image_size, 3), dtype=\"uint8\")\n",
        "all_im_prop = np.zeros((orig_nb_images, 4), dtype=\"float32\")\n",
        "\n",
        "for i in tqdm(range(0, orig_nb_images)):\n",
        "\n",
        "\tif(i < nb_train_2012):\n",
        "\t\tim = Image.open(\"VOCdevkit/VOC2012/JPEGImages/\"+train_list_2012[i]+\".jpg\")\n",
        "\telif(i < nb_train_2012+nb_train_2007):\n",
        "\t\tim = Image.open(\"VOCdevkit/VOC2007/JPEGImages/\"+train_list_2007[i - nb_train_2012]+\".jpg\")\n",
        "\telse:\n",
        "\t\tim = Image.open(\"VOCdevkit/VOC2007/JPEGImages/\"+test_list_2007[i - nb_train_2012 - nb_train_2007]+\".jpg\")\n",
        "\t\n",
        "\twidth, height = im.size\n",
        "\n",
        "\tim = make_square(im, image_size)\n",
        "\twidth2, height2 = im.size\n",
        "\n",
        "\tx_offset = int((width2 - width)*0.5)\n",
        "\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\tall_im_prop[i] = [x_offset, y_offset, width2, height2]\n",
        "\n",
        "\tim = im.resize((image_size,image_size))\n",
        "\tim_array = np.asarray(im)\n",
        "\tfor depth in range(0,3):\n",
        "\t\tall_im[i,:,:,depth] = im_array[:,:,depth]\n",
        "\n",
        "all_im.tofile(\"all_im.dat\")\n",
        "all_im_prop.tofile(\"all_im_prop.dat\")\n"
      ],
      "metadata": {
        "id": "VFxmRmpha4LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset summary statistics"
      ],
      "metadata": {
        "id": "4zsMWlIwFa8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/datasets/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"empty\"], dtype=\"str\")\n",
        "class_list_short = np.array([\"plane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"empty\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 4952\n",
        "image_size = 288\n",
        "nb_class = 20\n",
        "\n",
        "object_list = np.zeros((orig_nb_images,1+nb_class))\n",
        "\n",
        "for i in tqdm(range(0, orig_nb_images)):\n",
        "\t\n",
        "  if(i < nb_train_2012):\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i]+\".xml\")\n",
        "  elif(i < nb_train_2012+nb_train_2007):\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i - nb_train_2012]+\".xml\")\n",
        "  else:\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i - nb_train_2012 - nb_train_2007]+\".xml\")\n",
        "  root = tree.getroot()\n",
        "\n",
        "  root = tree.getroot()\n",
        "\n",
        "  k = 0\n",
        "  im_obj_list = root.findall(\"object\", namespaces=None)\n",
        "  object_list[i,0] = len(im_obj_list)\n",
        "  for obj in im_obj_list:\n",
        "    diff = obj.find(\"difficult\", namespaces=None)\n",
        "    if(diff.text == \"1\"):\n",
        "      object_list[i,0] -= 1\n",
        "      continue\n",
        "    oclass = obj.find(\"name\", namespaces=None)\n",
        "    int_class = np.where(class_list[:] == oclass.text)[0] + 1\n",
        "    object_list[i,int_class] += 1\n",
        "\n",
        "plt.rcParams.update({'font.size': 6})\n",
        "\n",
        "all_dat = np.sum(object_list[:,1:],axis=0)\n",
        "train_dat = np.sum(object_list[:orig_nb_images-nb_keep_val:,1:],axis=0)\n",
        "val_dat = np.sum(object_list[orig_nb_images-nb_keep_val:,1:],axis=0)\n",
        "\n",
        "print(\"%8s\"%(\"Total\"),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8s\"%class_list_short[k],end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(all_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%all_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(train_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%train_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"%8d\"%np.sum(val_dat),end=\"\")\n",
        "for k in range(0,nb_class):\n",
        "  print(\"%8d\"%val_dat[k], end=\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "plt.subplots(figsize=(6,2),dpi=190, constrained_layout=True)\n",
        "plt.bar(np.arange(0,nb_class)-0.2, all_dat, width=-0.2, align=\"center\", label=\"All\")\n",
        "plt.bar(np.arange(0,nb_class), train_dat, width=0.2, align=\"center\", label=\"Train\")\n",
        "plt.bar(np.arange(0,nb_class)+0.2, val_dat, width=0.2, align=\"center\", label=\"Val\")\n",
        "plt.xticks(np.arange(0,nb_class), class_list, fontsize=6, rotation = 45)\n",
        "plt.legend()\n",
        "#plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "all_dat = all_dat / np.max(all_dat)\n",
        "train_dat = train_dat / np.max(train_dat)\n",
        "val_dat = val_dat / np.max(val_dat)\n",
        "\n",
        "plt.subplots(figsize=(6,2),dpi=190, constrained_layout=True)\n",
        "plt.bar(np.arange(0,nb_class)-0.2, all_dat, width=0.2, align=\"center\", label=\"All\")\n",
        "plt.bar(np.arange(0,nb_class), train_dat, width=0.2, align=\"center\", label=\"Train\")\n",
        "plt.bar(np.arange(0,nb_class)+0.2, val_dat, width=0.2, align=\"center\", label=\"Val\")\n",
        "plt.xticks(range(0,nb_class), class_list, fontsize=6, rotation = 45)\n",
        "plt.legend()\n",
        "#plt.yscale('log')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MiR7lpk1Fn64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_im = np.fromfile(\"all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n"
      ],
      "metadata": {
        "id": "d7xBwuRwOOtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_start = 0 #define the beginning of the serie, then display nb_w * nb_h examples\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5.0,0.4), dpi=180, constrained_layout=True)\n",
        "ax.axis('off')\n",
        "fig.patch.set_facecolor('black')\n",
        "\n",
        "for k in range(0, nb_class):\n",
        "\tax.text(k%10*0.12, k//10*0.5, class_list_short[k], color=plt.cm.tab20(k), fontsize=8)\n",
        "\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(1.5*nb_w,1.5*nb_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for i in range(0, nb_h):\n",
        "  for j in range(0, nb_w):\n",
        "    i_d = j + i*nb_w + id_start\n",
        "\n",
        "    x_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images - nb_keep_val + i_d]\n",
        "\n",
        "    c_data = all_im[orig_nb_images - nb_keep_val + i_d]/255.0\n",
        "    ax[i,j].imshow(c_data)\n",
        "    ax[i,j].axis('off')\n",
        "\n",
        "    tree = ET.parse(\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[nb_test_2007 - nb_keep_val + i_d]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    obj_list = root.findall(\"object\", namespaces=None)\n",
        "    for obj in obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      if(diff.text == \"1\"):\n",
        "        continue\n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "      int_class = np.where(class_list[:] == oclass.text)[0][0]\n",
        "      xmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "      ymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "      xmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "      ymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\n",
        "      el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.8, ls=\"--\", fill=False, color=plt.cm.tab20(int_class), zorder=3)\n",
        "      c_patch = ax[i,j].add_patch(el)\n",
        "      c_text = ax[i,j].text(xmin+4, ymin+15, \"%s\"%(class_list_short[int_class]), c=plt.cm.tab20(int_class), fontsize=6, clip_on=True)\n",
        "      c_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "      c_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "\n",
        "#plt.savefig(\"target_moisaic.png\", dpi=250)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r31anWFsMBEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Free the RAM before going further in the notebook\n",
        "#A RUNTIME RESTART IS ADVISED\n",
        "\n",
        "del (all_im, all_im_prop)"
      ],
      "metadata": {
        "id": "ikflymkPn9X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"cianna_install\"></a>\n",
        "\n",
        "### **3\\. DL Framework (CIANNA) installation**"
      ],
      "metadata": {
        "id": "VcS4X04k4u9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n"
      ],
      "metadata": {
        "id": "bAGWKAMS5JhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /usr/local/cuda/samples/1_Utilities/deviceQuery\n",
        "\n",
        "make \n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository\n",
        "\n",
        "Choice of a specific commit to preserve the notebook from incompatibilty in futur CIANNA updates."
      ],
      "metadata": {
        "id": "OBuyj5WU5p8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA\n",
        "git checkout 93058ec"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "uGoKpzlO6cS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "pyth_ver=$(python3 -c 'import sys; print(\"%d.%d\"%(sys.version_info[:][0], sys.version_info[:][1]))')\n",
        "\n",
        "sed -i \"s/\\/lib.linux-x86_64-[0-9].[0-9]/\\/lib.linux-x86_64-$pyth_ver/g\" ex_script.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing CIANNA installation\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "tar -xvzf mnist.tar.gz"
      ],
      "metadata": {
        "id": "zZ_GKLD786w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "\n",
        "#Strictly equivalent to ex_script.py in the CIANNA repo \n",
        "\n",
        "cd /content/IRMIA_2022/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#Uncomment to access a locally compiled version\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "############################################################################\n",
        "##              Data reading (your mileage may vary)\n",
        "############################################################################\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "print (\"Reading inputs ... \", end = \"\", flush=True)\n",
        "\n",
        "#Loading binary files\n",
        "data = np.fromfile(\"mnist_dat/mnist_input.dat\", dtype=\"float32\")\n",
        "data = np.reshape(data, (80000,28*28))\n",
        "target = np.fromfile(\"mnist_dat/mnist_target.dat\", dtype=\"float32\")\n",
        "target = np.reshape(target, (80000,10))\n",
        "\n",
        "\n",
        "data_train = data[:60000,:]\n",
        "data_valid = data[60000:70000,:]\n",
        "data_test  = data[70000:80000,:]\n",
        "\n",
        "target_train = target[:60000,:]\n",
        "target_valid = target[60000:70000,:]\n",
        "target_test  = target[70000:80000,:]\n",
        "\n",
        "print (\"Done !\", flush=True)\n",
        "\n",
        "############################################################################\n",
        "##               CIANNA network construction and use\n",
        "############################################################################\n",
        "\n",
        "#Details about the functions and parameters are given in the GitHub Wiki\n",
        "\n",
        "cnn.init(in_dim=i_ar([28,28]), in_nb_ch=1, out_dim=10, \\\n",
        "\t\tbias=0.1, b_size=24, comp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP32C_FP32A\") #Change to C_BLAS or C_NAIV\n",
        "\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", size=60000, input=data_train, target=target_train)\n",
        "cnn.create_dataset(\"VALID\", size=10000, input=data_valid, target=target_valid)\n",
        "cnn.create_dataset(\"TEST\", size=10000, input=data_test, target=target_test)\n",
        "\n",
        "#Used to load a saved network at a given epoch\n",
        "#With load_step = 0, the network is trained from scratch\n",
        "load_step = 0\n",
        "if(load_step > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%(load_step), load_step)\n",
        "else:\n",
        "  cnn.conv(f_size=i_ar([5,5]), nb_filters=32, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.conv(f_size=i_ar([5,5]), nb_filters=64, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "  cnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "  cnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.5)\n",
        "  cnn.dense(nb_neurons=128, activation=\"RELU\", drop_rate=0.2)\n",
        "  cnn.dense(nb_neurons=10, activation=\"SMAX\")\n",
        "\n",
        "cnn.train(nb_epoch=10, learning_rate=0.0004, momentum=0.9, confmat=1, save_every=0)\n",
        "#Change save_every in previous function to save network weights\n",
        "cnn.perf_eval()\n",
        "\n",
        "\n",
        "#Uncomment to save network prediction\n",
        "cnn.forward(repeat=1, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "del (data_train, target_train, data_valid, target_valid, data_test, target_test)\n",
        "\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "2L-7ZffT9Ayq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c1VcemANg-ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A - Simple classifier on PASCAL VOC**"
      ],
      "metadata": {
        "id": "J8lC3HBMDdO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1\\. Train and valid data generation**"
      ],
      "metadata": {
        "id": "Xb_7nGR4EqiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "mkdir classifier\n",
        "cd classifier"
      ],
      "metadata": {
        "id": "YSqToJLcq6nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic data generator"
      ],
      "metadata": {
        "id": "f9fITGtbE0OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/classifier/data_gen.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007\t= np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "def roll_zeropad(a, shift):\n",
        "\ta = np.roll(a, shift[0], axis = 1)\n",
        "\tif(shift[0] >= 0):\n",
        "\t\ta[:,0:shift[0]] = 0\n",
        "\telse:\n",
        "\t\ta[:,image_size_orig+shift[0]:] = 0\n",
        "\ta = np.roll(a, shift[1], axis = 0)\n",
        "\tif(shift[1] >= 0):\n",
        "\t\ta[0:shift[1],:] = 0\n",
        "\telse:\n",
        "\t\ta[image_size_orig+shift[1]:,:] = 0\n",
        "\treturn a\n",
        "\n",
        "\n",
        "def init_data_gen():\n",
        "\tglobal nb_train_2012, nb_train_2007, nb_test_2007, orig_nb_images, nb_class\n",
        "\tglobal nb_images_per_batch, nb_keep_val, nb_obj_val, image_size, image_size_orig, seq_iaa\n",
        "\tglobal input_data, targets, input_val, targets_val, all_im, all_im_prop\n",
        "\n",
        "\tnb_train_2012 = 11540\n",
        "\tnb_train_2007 = 5011\n",
        "\tnb_test_2007 = 4952\n",
        "\torig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "\tnb_keep_val = 4952 #keep in 2007 test\n",
        "\tnb_images_per_batch = 4000\n",
        "\tnb_obj_val = 11831\n",
        "\n",
        "\tnb_class = 20\n",
        "\timage_size_orig = 288\n",
        "\timage_size = 96\n",
        "\n",
        "\n",
        "\tseq_iaa = iaa.Sequential([\n",
        "\t\t\tiaa.Fliplr(0.5),\n",
        "\t\t\tiaa.Flipud(0.1),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
        "\t\t\tiaa.LinearContrast((0.75, 1.5)),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
        "\t\t\tiaa.Multiply((0.8,1.2), per_channel=0.2),\n",
        "\t\t\tiaa.Affine(translate_percent={\"x\": (-0.1,0.1), \"y\": (-0.1,0.1)}),\n",
        "\t\t\tiaa.Sometimes(0.5,iaa.Affine(scale={\"x\": (0.9,1.1), \"y\": (0.9,1.1)})),\n",
        "\t\t\tiaa.Sometimes(0.2,iaa.Affine(rotate=(-10,10),shear=(-6,6))),\n",
        "\t\t\tiaa.Sometimes(0.02,iaa.Grayscale(alpha=(0.0, 1.0)))\n",
        "\t\t])\n",
        "\n",
        "\tall_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "\tall_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "\tall_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "\tall_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "\tinput_data = np.zeros((nb_images_per_batch,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets = np.zeros((nb_images_per_batch,nb_class), dtype=\"float32\")\n",
        "\n",
        "\tinput_val = np.zeros((nb_obj_val,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets_val = np.zeros((nb_obj_val,nb_class), dtype=\"float32\")\n",
        "\n",
        "\n",
        "def create_train_batch(visual_w=0,visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\tfor i in range(0, nb_images_per_batch):\n",
        "\t\t\n",
        "\t\ti_d = np.random.randint(0,orig_nb_images - nb_keep_val)\n",
        "\t\tif(i_d < nb_train_2012):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d]+\".xml\")\n",
        "\t\telif(i_d < nb_train_2012+nb_train_2007):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d - nb_train_2012]+\".xml\")\n",
        "\t\telse:\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2012 - nb_train_2007]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tpatch = np.copy(all_im[i_d])\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\tk = 0\n",
        "\t\tfor obj in im_obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\n",
        "\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\n",
        "\t\t\t\tk += 1\n",
        "\t\t\t\t\n",
        "\t\tnb_obj = k\n",
        "\t\tif(nb_obj == 0):\n",
        "\t\t\ti -= 1\n",
        "\t\t\tcontinue\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tobj_id = np.random.randint(0,nb_obj)\n",
        "\t\tk = 0\n",
        "\t\tfor obj in im_obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\n",
        "\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\tif(obj_id == k):\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\tk += 1\n",
        "\t\t\n",
        "\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\tint_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "\t\tl_targ = np.zeros(nb_class)\n",
        "\t\tl_targ[int_class] = 1\n",
        "\t\ttargets[i,:] = np.copy(l_targ)\n",
        "\t\t\n",
        "\t\tim = Image.fromarray(patch)\n",
        "\t\tmax_size = max((xmax-xmin),(ymax-ymin))\n",
        "\t\tc_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "\t\txmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "\t\tymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "\t\t\n",
        "\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\n",
        "\t\tpatch_aug = seq_iaa(image=im_array)\n",
        "\t\t\n",
        "\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\n",
        "\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\n",
        "\t\t\tax[c_x,c_y].imshow(patch_aug)\n",
        "\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\tc_text = ax[c_x,c_y].text(image_size/2, 8, \"%s\"%(class_list_short[int_class]),\n",
        "\t\t\t\tha=\"center\", fontsize=10, clip_on=True, color=\"white\")\n",
        "\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "\t\t\t\n",
        "\t\t\tvisual_iter += 1\n",
        "\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\treturn\n",
        "\t\t\n",
        "\t\tfor depth in range(0,3):\n",
        "\t\t\tinput_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = patch_aug[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\n",
        "\treturn input_data, targets\n",
        "\n",
        "\n",
        "def create_val_batch(visual_w=0, visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\n",
        "\tk = 0\n",
        "\tfor i in range(0, nb_keep_val):\n",
        "\t\t\t\t\n",
        "\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[nb_test_2007 - nb_keep_val + i]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tpatch = np.copy(all_im[nb_train_2007 + nb_train_2012 + nb_test_2007 - nb_keep_val + i])\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[nb_train_2007 + nb_train_2012 + nb_test_2007 - nb_keep_val + i]\n",
        "\n",
        "\t\tim = Image.fromarray(patch)\n",
        "\n",
        "\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\tfor obj in im_obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\n",
        "\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\t\tint_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "\t\t\tl_targ = np.zeros(nb_class)\n",
        "\t\t\tl_targ[int_class] = 1\n",
        "\t\t\ttargets_val[k,:] = np.copy(l_targ)\n",
        "\n",
        "\t\t\tmax_size = max((xmax-xmin),(ymax-ymin))\n",
        "\t\t\tc_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "\t\t\txmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "\t\t\tymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "\t\t\n",
        "\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\n",
        "\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\n",
        "\t\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\t\n",
        "\t\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\t\n",
        "\t\t\t\tax[c_x,c_y].imshow(im_array)\n",
        "\t\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\t\tc_text = ax[c_x,c_y].text(image_size/2, 8, \"%s\"%(class_list_short[int_class]),\n",
        "\t\t\t\t\tha=\"center\", fontsize=10, clip_on=True, color=\"white\")\n",
        "\t\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "\t\t\t\t\n",
        "\t\t\t\tvisual_iter += 1\n",
        "\t\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\t\tplt.show()\n",
        "\t\t\t\t\treturn\n",
        "\t\t\n",
        "\t\t\tfor depth in range(0,3):\n",
        "\t\t\t\tinput_val[k,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\tk+=1\n",
        "\t\t\t#print (k)\n",
        "\t\t\n",
        "\treturn input_val, targets_val\n",
        "\n",
        "def free_data_gen():\n",
        "  global all_im, all_im_prop, input_data, targets, input_val, targets_val\n",
        "  del (all_im, all_im_prop, input_data, targets, input_val, targets_val)\n",
        "  return\n"
      ],
      "metadata": {
        "id": "1Mp7fVUBE30T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training image examples"
      ],
      "metadata": {
        "id": "s1PVa19yEjMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/classifier/test_gen.py\n",
        "\n",
        "import data_gen as gn1\n",
        "\n",
        "gn1.init_data_gen()\n",
        "\n",
        "print(\"Random augmented training examples\")\n",
        "gn1.create_train_batch(4,3)\n",
        "\n",
        "print(\"\\nOrdered validation examples\")\n",
        "gn1.create_val_batch(4,3)\n",
        "\n",
        "gn1.free_data_gen()\n"
      ],
      "metadata": {
        "id": "Bzv7yFvG1ajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Might need to reload the notebook execution environment to unload previous data_gen afters changes\n",
        "%cd /content/IRMIA_2022/classifier/\n",
        "\n",
        "%run test_gen.py\n"
      ],
      "metadata": {
        "id": "r-U9dkltuqih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2\\.Training the classifier**\n"
      ],
      "metadata": {
        "id": "dFlwUL7eE6Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/classifier/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import data_gen as gn1\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = gn1.create_train_batch()\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images_per_batch, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "nb_images_per_batch = 4000\n",
        "nb_obj_val = 11831\n",
        "nb_class = 20\n",
        "image_size = 96\n",
        "\n",
        "nb_augm = 1000\n",
        "epoch_per_augm = 5\n",
        "\n",
        "# -1 will load the provided pre trained network.\n",
        "# Switch to 0 for training from scratch, \n",
        "# or to the value corresponding to an existing network save.\n",
        "load_epoch = -1\n",
        "# Increase the number of augmentation for training t\n",
        "# to continue training of the pre trained network\n",
        "if(load_epoch == -1):\n",
        "\tnb_augm = 2\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class,\n",
        "\t b_size=16, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "print (\"Loading the dataset ...\")\n",
        "\n",
        "gn1.init_data_gen()\n",
        "\n",
        "input_data, targets = gn1.create_train_batch()\n",
        "input_val, targets_val = gn1.create_val_batch()\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_batch, input_data[:,:], targets[:,:])\n",
        "cnn.create_dataset(\"VALID\", nb_obj_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "if(load_epoch == -1):\n",
        "\tcnn.load(\"/content/IRMIA_2022/pre_trained_nets/classifier_net0_s8000.dat\",8000, bin=1)\n",
        "elif(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=16, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=32, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=64, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.2)\n",
        "\tcnn.dense(nb_neurons=nb_class, activation=\"SMAX\")\n",
        "\n",
        "\n",
        "for batch_augm in range(0,nb_augm): #will run from 1000 x 5 epochs\n",
        "\t\t\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\t\n",
        "\tcnn.train(nb_epoch=epoch_per_augm, learning_rate=0.003, end_learning_rate=0.00005, \n",
        "\t\t\t\tdecay=0.001, momentum=0.5, shuffle_every=1, confmat=1, \n",
        "\t\t\t\tcontrol_interv=5, save_every=100, silent=1, TC_scale_factor=16.0, save_bin=1)\n",
        "\tif(batch_augm == 0):\n",
        "\t\tcnn.perf_eval()\n",
        "\n",
        "\tt.join()\n",
        "\t\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "\n",
        "gn1.free_data_gen()\n",
        "del (input_data, targets, input_val, targets_val)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "hqz7tMvoz5mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "os4SbssRhBA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B - Sliding window detector**"
      ],
      "metadata": {
        "id": "R1hzOMVAFExp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1\\. Train and valid data generation**\n"
      ],
      "metadata": {
        "id": "W-aEcbXVFQGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "mkdir sliding_window\n",
        "cd sliding_window"
      ],
      "metadata": {
        "id": "A9n1JmnmFkHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding a \"background class\" to the data generator"
      ],
      "metadata": {
        "id": "NyKOs6O4F9gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/sliding_window/data_gen.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"empty\"], dtype=\"str\")\n",
        "class_list_short = np.array([\"plane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"empty\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007\t= np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "\n",
        "def fct_inter(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\n",
        "\treturn float(inter_2d)\n",
        "\n",
        "\n",
        "def init_data_gen():\n",
        "\tglobal nb_train_2012, nb_train_2007, nb_test_2007, orig_nb_images, nb_class\n",
        "\tglobal nb_images_per_batch, nb_keep_val, nb_empty_val, nb_obj_val, image_size, image_size_orig, seq_iaa\n",
        "\tglobal input_data, targets, input_val, targets_val, all_im, all_im_prop\n",
        "\n",
        "\tnb_train_2012 = 11540\n",
        "\tnb_train_2007 = 5011\n",
        "\tnb_test_2007 = 4952\n",
        "\torig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "\tnb_keep_val = 4952 #keep in 2007 test\n",
        "\tnb_images_per_batch = 4000\n",
        "\tnb_obj_val = 11831\n",
        "\tnb_empty_val = 1000\n",
        "\n",
        "\tnb_class = 20\n",
        "\timage_size_orig = 288\n",
        "\timage_size = 96\n",
        "\n",
        "\n",
        "\tseq_iaa = iaa.Sequential([\n",
        "\t\t\tiaa.Fliplr(0.5),\n",
        "\t\t\tiaa.Flipud(0.1),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
        "\t\t\tiaa.LinearContrast((0.75, 1.5)),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
        "\t\t\tiaa.Multiply((0.8,1.2), per_channel=0.2),\n",
        "\t\t\tiaa.Affine(translate_percent={\"x\": (-0.1,0.1), \"y\": (-0.1,0.1)}),\n",
        "\t\t\tiaa.Sometimes(0.5,iaa.Affine(scale={\"x\": (0.9,1.1), \"y\": (0.9,1.1)})),\n",
        "\t\t\tiaa.Sometimes(0.2,iaa.Affine(rotate=(-10,10),shear=(-6,6))),\n",
        "\t\t\tiaa.Sometimes(0.02,iaa.Grayscale(alpha=(0.0, 1.0)))\n",
        "\t\t])\n",
        "\n",
        "\tall_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "\tall_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "\tall_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "\tall_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "\tinput_data = np.zeros((nb_images_per_batch,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets = np.zeros((nb_images_per_batch,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "\tinput_val = np.zeros((nb_obj_val+nb_empty_val,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets_val = np.zeros((nb_obj_val+nb_empty_val,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "\n",
        "def create_train_batch(visual_w=0,visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\tfor i in range(0, nb_images_per_batch):\n",
        "\t\t\n",
        "\t\ti_d = np.random.randint(0,orig_nb_images - nb_keep_val)\n",
        "\t\tif(i_d < nb_train_2012):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d]+\".xml\")\n",
        "\t\telif(i_d < nb_train_2012+nb_train_2007):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d - nb_train_2012]+\".xml\")\n",
        "\t\telse:\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2012 - nb_train_2007]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tpatch = np.copy(all_im[i_d])\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "\t\t# classical object cutout\n",
        "\t\tif(np.random.random() > 0.2):\n",
        "\t\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\t\tk = 0\n",
        "\t\t\tfor obj in im_obj_list:\n",
        "\t\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tk += 1\n",
        "\t\t\t\t\t\n",
        "\t\t\tnb_obj = k\n",
        "\t\t\tif(nb_obj == 0):\n",
        "\t\t\t\ti -= 1\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\tobj_id = np.random.randint(0,nb_obj)\n",
        "\t\t\tk = 0\n",
        "\t\t\tfor obj in im_obj_list:\n",
        "\t\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\tif(obj_id == k):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tk += 1\n",
        "\t\t\t\n",
        "\t\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\t\tint_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "\t\t\tl_targ = np.zeros(nb_class+1)\n",
        "\t\t\tl_targ[int_class] = 1\n",
        "\t\t\ttargets[i,:] = np.copy(l_targ)\n",
        "\t\t\t\n",
        "\t\t\tim = Image.fromarray(patch)\n",
        "\t\t\tmax_size = max((xmax-xmin),(ymax-ymin))\n",
        "\t\t\tc_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "\t\t\txmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "\t\t\tymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "\t\t\t\n",
        "\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\tfound = 0\n",
        "\t\t\tl_size = 160\n",
        "\t\t\ttry_per_size = 10\n",
        "\n",
        "\t\t\tint_class = 20\n",
        "\t\t\tl_targ = np.zeros(nb_class+1)\n",
        "\t\t\tl_targ[nb_class] = 1\n",
        "\t\t\ttargets[i,:] = np.copy(l_targ)\n",
        "\n",
        "\t\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\t\tbox_list = np.zeros((len(im_obj_list),4))\n",
        "\t\t\tk = 0\n",
        "\t\t\tfor obj in im_obj_list:\n",
        "\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\tbox_list[k,:] = np.array([xmin,ymin,xmax,ymax])\n",
        "\t\t\t\tk += 1\n",
        "\n",
        "\t\t\tcount_per_size = 0\n",
        "\t\t\twhile((not found) and (l_size >= 0)):\n",
        "\t\t\t\tsize = l_size + 32\n",
        "\n",
        "\t\t\t\tc_x = np.random.random()*(image_size_orig - size) + size/2\n",
        "\t\t\t\tc_y = np.random.random()*(image_size_orig - size) + size/2\n",
        "\n",
        "\t\t\t\txmin = int(c_x - 0.5*size); xmax = int(c_x + 0.5*size)\n",
        "\t\t\t\tymin = int(c_y - 0.5*size); ymax = int(c_y + 0.5*size)\n",
        "\n",
        "\t\t\t\tc_box = np.array([xmin, ymin, xmax, ymax])\n",
        "\n",
        "\t\t\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\t\t\tinter_count = 0\n",
        "\t\t\t\tfor l in range(0,len(im_obj_list)):\n",
        "\t\t\t\t\tloc_inter = fct_inter(c_box, box_list[l,:])\n",
        "\t\t\t\t\tif(loc_inter > 0.0):\n",
        "\t\t\t\t\t\tinter_count += 1\n",
        "\n",
        "\t\t\t\tif(inter_count == 0):\n",
        "\t\t\t\t\tfound = 1\n",
        "\n",
        "\t\t\t\tcount_per_size += 1\n",
        "\t\t\t\tif(count_per_size >= try_per_size):\n",
        "\t\t\t\t\tcount_per_size = 0\n",
        "\t\t\t\t\tl_size -= 32\n",
        "\n",
        "\t\t\tif(not found):\n",
        "\t\t\t\tim_array = np.zeros((image_size,image_size,3),dtype=\"uint8\")\n",
        "\n",
        "\t\t\telse:\n",
        "\n",
        "\t\t\t\tim = Image.fromarray(patch)\n",
        "\n",
        "\t\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "\t\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\n",
        "\t\t\t\tim_array = np.asarray(im_loc)\n",
        "  \n",
        "\t\tpatch_aug = seq_iaa(image=im_array)\n",
        "\t\t\n",
        "\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\n",
        "\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\n",
        "\t\t\tax[c_x,c_y].imshow(patch_aug)\n",
        "\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\tc_text = ax[c_x,c_y].text(image_size/2, 8, class_list_short[int_class],\n",
        "\t\t\t\tha=\"center\", fontsize=10, clip_on=True, color=\"white\")\n",
        "\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t path_effects.Normal()])\n",
        "\t\t\t\n",
        "\t\t\tvisual_iter += 1\n",
        "\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\treturn\n",
        "\t\t\n",
        "\t\tfor depth in range(0,3):\n",
        "\t\t\tinput_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = patch_aug[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\n",
        "\treturn input_data, targets\n",
        "\n",
        "\n",
        "def create_val_batch(visual_w=0, visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\n",
        "\tloc = 0\n",
        "\tfor i in range(0, nb_keep_val):\n",
        "\t\t\t\t\n",
        "\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[nb_test_2007 - nb_keep_val + i]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tpatch = np.copy(all_im[nb_train_2007 + nb_train_2012 + nb_test_2007 - nb_keep_val + i])\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[nb_train_2007 + nb_train_2012 + nb_test_2007 - nb_keep_val + i]\n",
        "\n",
        "\t\tim = Image.fromarray(patch)\n",
        "\n",
        "\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\tfor obj in im_obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\t\t\n",
        "\t\t\t\twidth = (xmax-xmin); height = (ymax-ymin)\n",
        "\t\t\t\tif(width*height < 196):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\t\tint_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "\t\t\tl_targ = np.zeros(nb_class+1)\n",
        "\t\t\tl_targ[int_class] = 1\n",
        "\t\t\ttargets_val[loc,:] = np.copy(l_targ)\n",
        "\n",
        "\t\t\tmax_size = max((xmax-xmin),(ymax-ymin))\n",
        "\t\t\tc_x = (xmin+xmax)/2.0; c_y = (ymin+ymax)/2.0\n",
        "\t\t\txmin = max(0,int(c_x - 0.5*max_size)); xmax = min(image_size_orig,int(c_x + 0.5*max_size))\n",
        "\t\t\tymin = max(0,int(c_y - 0.5*max_size)); ymax = min(image_size_orig,int(c_y + 0.5*max_size))\n",
        "\t\t\n",
        "\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\t\n",
        "\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\n",
        "\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\n",
        "\t\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\t\n",
        "\t\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\t\n",
        "\t\t\t\tax[c_x,c_y].imshow(im_array)\n",
        "\t\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\t\tc_text = ax[c_x,c_y].text(image_size/2, 8, class_list_short[int_class],\n",
        "\t\t\t\t\tha=\"center\", fontsize=10, clip_on=True, color=\"white\")\n",
        "\t\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t path_effects.Normal()])\n",
        "\t\t\t\t\n",
        "\t\t\t\tvisual_iter += 1\n",
        "\t\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\t\tplt.show()\n",
        "\t\t\t\t\treturn\n",
        "\t\t\n",
        "\t\t\tfor depth in range(0,3):\n",
        "\t\t\t\tinput_val[loc,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\tloc+=1\n",
        "\tprint (loc)\n",
        "\t\n",
        "\tfor i in range(0, nb_empty_val):\n",
        "\n",
        "\t\ti_d = np.random.randint(0,nb_keep_val)\n",
        "\n",
        "\t\tpatch = np.copy(all_im[orig_nb_images-nb_keep_val + i_d])\n",
        "\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images - nb_keep_val + i_d]\n",
        "\n",
        "\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[nb_test_2007 - nb_keep_val + i_d]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\n",
        "\t\tim = Image.fromarray(patch)\n",
        "\n",
        "\t\tfound = 0\n",
        "\t\tl_size = 160\n",
        "\t\ttry_per_size = 10\n",
        "\n",
        "\t\tint_class = 20\n",
        "\t\tl_targ = np.zeros(nb_class+1)\n",
        "\t\tl_targ[nb_class] = 1\n",
        "\t\ttargets_val[loc+i,:] = np.copy(l_targ)\n",
        "\n",
        "\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\tbox_list = np.zeros((len(im_obj_list),4))\n",
        "\t\tk = 0\n",
        "\t\tfor obj in im_obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\n",
        "\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size_orig/width2\n",
        "\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size_orig/height2\n",
        "\t\t\tbox_list[k,:] = np.array([xmin,ymin,xmax,ymax])\n",
        "\t\t\tk += 1\n",
        "\n",
        "\t\tcount_per_size = 0\n",
        "\t\twhile((not found) and (l_size >= 0)):\n",
        "\t\t\tsize = l_size + 32\n",
        "\t\t\t\n",
        "\t\t\tc_x = np.random.random()*(image_size_orig - size) + size/2\n",
        "\t\t\tc_y = np.random.random()*(image_size_orig - size) + size/2\n",
        "\t\t\t\n",
        "\t\t\txmin = int(c_x - 0.5*size); xmax = int(c_x + 0.5*size)\n",
        "\t\t\tymin = int(c_y - 0.5*size); ymax = int(c_y + 0.5*size)\n",
        "\t\t\t\n",
        "\t\t\tc_box = np.array([xmin, ymin, xmax, ymax])\n",
        "\t\t\t\n",
        "\t\t\tim_obj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\t\tinter_count = 0\n",
        "\t\t\tfor l in range(0,len(im_obj_list)):\n",
        "\t\t\t\tloc_inter = fct_inter(c_box, box_list[l,:])\n",
        "\t\t\t\tif(loc_inter > 0.0):\n",
        "\t\t\t\t\tinter_count += 1\n",
        "\t\t\t\n",
        "\t\t\tif(inter_count == 0):\n",
        "\t\t\t\tfound = 1\n",
        "\t\t\t\n",
        "\t\t\tcount_per_size += 1\n",
        "\t\t\tif(count_per_size >= try_per_size):\n",
        "\t\t\t\tcount_per_size = 0\n",
        "\t\t\t\tl_size -= 32\n",
        "\n",
        "\t\tif(not found):\n",
        "\t\t\tim_array = np.zeros((image_size,image_size,3), dtype=\"float32\")\n",
        "\t\t\t\n",
        "\t\telse:\n",
        "\t\t\t\n",
        "\t\t\tim = Image.fromarray(patch)\n",
        "\n",
        "\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\t\n",
        "\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\t\n",
        "\t\t\n",
        "\t\tfor depth in range(0,3):\n",
        "\t\t\tinput_val[loc+i,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\n",
        "\treturn input_val, targets_val\n",
        "\n",
        "\n",
        "def free_data_gen():\n",
        "  global all_im, all_im_prop, input_data, targets, input_val, targets_val\n",
        "  del (all_im, all_im_prop, input_data, targets, input_val, targets_val)\n",
        "  return\n"
      ],
      "metadata": {
        "id": "Bzi-xvGGF1RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training image examples"
      ],
      "metadata": {
        "id": "5PQlbbsSMQIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/sliding_window/test_gen.py\n",
        "\n",
        "import data_gen as gn2\n",
        "\n",
        "gn2.init_data_gen()\n",
        "\n",
        "print(\"Random augmented training examples\")\n",
        "gn2.create_train_batch(4,3)\n",
        "\n",
        "print(\"\\nOrdered validation examples\")\n",
        "gn2.create_val_batch(4,3)\n",
        "\n",
        "gn2.free_data_gen()\n"
      ],
      "metadata": {
        "id": "8iP12KrPMQ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Might need to reload the notebook execution environment to unload previous data_gen afters changes\n",
        "%cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "%run test_gen.py"
      ],
      "metadata": {
        "id": "zQ7PdsfBMnha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2\\. Training the detection classifier**"
      ],
      "metadata": {
        "id": "B58RU8bBS-mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import data_gen as gn2\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = gn2.create_train_batch()\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images_per_batch, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "nb_images_per_batch = 4000\n",
        "nb_obj_val = 11831\n",
        "nb_empty_val = 1000\n",
        "nb_class = 20\n",
        "image_size = 96\n",
        "\n",
        "nb_augm = 1000\n",
        "epoch_per_augm = 5\n",
        "\n",
        "# -1 will load the provided pre trained network.\n",
        "# Switch to 0 for training from scratch, \n",
        "# or to the value corresponding to an existing network save.\n",
        "load_epoch = -1\n",
        "# Increase the number of augmentation for training t\n",
        "# to continue training of the pre trained network\n",
        "if(load_epoch == -1):\n",
        "\tnb_augm = 2\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class+1,\n",
        "\t b_size=32, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "print (\"Loading the dataset ...\")\n",
        "\n",
        "gn2.init_data_gen()\n",
        "\n",
        "input_data, targets = gn2.create_train_batch()\n",
        "input_val, targets_val = gn2.create_val_batch()\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_batch, input_data[:,:], targets[:,:])\n",
        "cnn.create_dataset(\"VALID\", nb_obj_val + nb_empty_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "\n",
        "if(load_epoch == -1):\n",
        "\tcnn.load(\"/content/IRMIA_2022/pre_trained_nets/sliding_window_net0_s8000.dat\",8000, bin=1)\n",
        "elif(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=16, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=32, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=64, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.2)\n",
        "\tcnn.dense(nb_neurons=nb_class+1, activation=\"SMAX\")\n",
        "\n",
        "\n",
        "for batch_augm in range(0,nb_augm):\n",
        "\t\t\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\t\n",
        "\tcnn.train(nb_epoch=epoch_per_augm, learning_rate=0.0015, end_learning_rate=0.00005, \n",
        "\t\t\t\tdecay=0.001, momentum=0.5, shuffle_every=1, confmat=1, \n",
        "\t\t\t\tcontrol_interv=5, save_every=100, silent=1, TC_scale_factor=16.0, save_bin=1)\n",
        "\tif(batch_augm == 0):\n",
        "\t\tcnn.perf_eval()\n",
        "\n",
        "\tt.join()\n",
        "\t\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "\n",
        "gn2.free_data_gen()\n",
        "del (input_data, targets, input_val, targets_val)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "EGaf2q77TGR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3\\. Sliding window prediction**"
      ],
      "metadata": {
        "id": "ZuU0yjzCnNar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regions definition and network inference"
      ],
      "metadata": {
        "id": "X9LpPb72qd_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import re\n",
        "import os\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "\tload_epoch = int(sys.argv[1])\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"empty\"], dtype=\"str\")\n",
        "class_list_short = np.array([\"plane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"empty\"])\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 400 # Lower than the actual number of example to keep RAM low enough\n",
        "\n",
        "nb_class = 20\n",
        "image_size_orig = 288\n",
        "image_size = 96\n",
        "\n",
        "frac_size = np.array([288,144,72])\n",
        "frac_stride = np.array([0,72,36])\n",
        "\n",
        "print (\"Loading the dataset ...\")\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "nb_regions_per_im = 1\n",
        "for l in range(1,np.size(frac_size)):\n",
        "\tnb_regions_per_im += ((image_size_orig-frac_size[l])/frac_stride[l] + 1)**2\n",
        "\n",
        "print (nb_regions_per_im)\n",
        "all_nb_test_images = int(nb_regions_per_im*nb_keep_val)\n",
        "\n",
        "print (all_nb_test_images)\n",
        "\n",
        "input_test = np.zeros((all_nb_test_images,image_size*image_size*3), dtype=\"float32\")\n",
        "targets_test = np.zeros((all_nb_test_images,nb_class+1), dtype=\"float32\")\n",
        "\n",
        "k = 0\n",
        "for i in tqdm(range(0, nb_keep_val)):\n",
        "\t\n",
        "\ti_d = orig_nb_images - nb_keep_val + i\n",
        "\t\n",
        "\tpatch = np.copy(all_im[i_d])\n",
        "\t\n",
        "\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\t\n",
        "\tim = Image.fromarray(patch)\n",
        "\t\n",
        "\tfor l in range(0, np.size(frac_size)):\n",
        "\t\t\n",
        "\t\tif(l == 0):\n",
        "\t\t\tnb_reg = 1\n",
        "\t\telse:\n",
        "\t\t\tnb_reg = int((image_size_orig-frac_size[l])/frac_stride[l] + 1)\n",
        "\t\t\n",
        "\t\tfor l_x in range(0, nb_reg):\n",
        "\t\t\tfor l_y in range(0, nb_reg):\n",
        "\t\t\t\t\n",
        "\t\t\t\txmin = l_x * frac_stride[l]\n",
        "\t\t\t\tymin = l_y * frac_stride[l]\n",
        "\t\t\t\txmax = xmin + frac_size[l]\n",
        "\t\t\t\tymax = ymin + frac_size[l]\n",
        "\t\t\t\t\n",
        "\t\t\t\tim_loc = im.crop((xmin,ymin,xmax,ymax))\n",
        "\t\t\t\tim_loc = im_loc.resize((image_size,image_size), Image.NEAREST)\n",
        "\t\t\t\t\n",
        "\t\t\t\tim_array = np.asarray(im_loc)\n",
        "\t\t\t\t\n",
        "\t\t\t\tfor depth in range(0,3):\n",
        "\t\t\t\t\tinput_test[k,depth*image_size*image_size:(depth+1)*image_size*image_size] = im_array[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\t\tk += 1\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class+1,\n",
        "\t b_size=32, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "cnn.create_dataset(\"TEST\", all_nb_test_images, input_test[:,:], targets_test[:,:])\n",
        "\n",
        "load_epoch = -1\n",
        "if(load_epoch == -1):\n",
        "\tcnn.load(\"/content/IRMIA_2022/pre_trained_nets/sliding_window_net0_s8000.dat\",8000, bin=1)\n",
        "\tload_epoch = 8000\n",
        "elif(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\tfiles = os.listdir(\"net_save/\")\n",
        "\tpaths = [os.path.join(\"net_save/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent save : \" + path)\n",
        "\t\n",
        "\tcnn.load(path, r_load_epoch[0], bin=1)\n",
        "\t\n",
        "cnn.forward(no_error=1, saving=2)\n",
        "\n",
        "del (all_im, all_im_prop, input_test, targets_test)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "FCTCRmmqnN7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction vizualisation"
      ],
      "metadata": {
        "id": "Wct5u9N6qmQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/sliding_window/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.patheffects as path_effects\n",
        "\n",
        "import re\n",
        "import bisect\n",
        "import os\n",
        "\n",
        "import sys\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"empty\"], dtype=\"str\")\n",
        "class_list_short = np.array([\"plane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"empty\"])\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "nb_keep_val = 400 #keep in 2007 test\n",
        "\n",
        "nb_class = 20\n",
        "image_size_orig = 288\n",
        "image_size = 96\n",
        "\n",
        "frac_size = np.array([288,144,72])\n",
        "frac_stride = np.array([0,72,36])\n",
        "nb_reg_per_frac = np.array([1,0,0])\n",
        "cumul_nb_per_frac = np.array([1,0,0])\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size_orig, image_size_orig, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "nb_regions_per_im = 1\n",
        "for l in range(1,np.size(frac_size)):\n",
        "\tnb_reg_per_frac[l] = ((image_size_orig-frac_size[l])/frac_stride[l] + 1)\n",
        "\tnb_regions_per_im += nb_reg_per_frac[l]**2\n",
        "\tcumul_nb_per_frac[l] = nb_regions_per_im\n",
        "\n",
        "print (nb_reg_per_frac, cumul_nb_per_frac)\n",
        "\n",
        "load_epoch = 0\n",
        "if(load_epoch == 0):\n",
        "\tfiles = os.listdir(\"fwd_res/\")\n",
        "\tpaths = [os.path.join(\"fwd_res/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[_s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent prediction : \" + path)\n",
        "\t\n",
        "\tload_epoch = r_load_epoch[0]\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "\n",
        "pred_data = np.reshape(pred_raw,(nb_keep_val, int(nb_regions_per_im), 22))\n",
        "\n",
        "width_list = np.array([2.0, 1.5, 1.0])\n"
      ],
      "metadata": {
        "id": "HfToMT80qbuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i_d = 0\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(2*nb_w,2*nb_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for l_h in range(0, nb_h):\n",
        "  for l_w in range(0, nb_w):\n",
        "    loc = i_d + l_w + l_h*nb_w\n",
        "    patch = np.copy(all_im[orig_nb_images - nb_keep_val + loc])\n",
        "    \n",
        "    ax[l_h,l_w].imshow(patch)\n",
        "    ax[l_h,l_w].axis('off')\n",
        "\n",
        "    for l in range(0,int(nb_regions_per_im)):\n",
        "      max_loc = np.argmax(pred_data[loc,l,:])\n",
        "      max_val = np.max(pred_data[loc,l,:])\n",
        "      if(l == 0 or (max_val > 0.9 and max_loc < nb_class)):\n",
        "        \n",
        "        index = bisect.bisect(cumul_nb_per_frac, l)\n",
        "        \n",
        "        if(l > 0):\n",
        "          i_l = l - cumul_nb_per_frac[index-1]\n",
        "        else:\n",
        "          i_l = 0\n",
        "        i_x = i_l // nb_reg_per_frac[index]\n",
        "        i_y = i_l % nb_reg_per_frac[index]\n",
        "        \n",
        "        xmin = i_x * frac_stride[index] - 0.5 + 2*index; ymin = i_y * frac_stride[index] - 0.5 + 2*index\n",
        "        xmax = xmin + frac_size[index] - 4*index; ymax = ymin + frac_size[index] - 4*index\n",
        "        el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth= width_list[index], fill=False, color=plt.cm.tab20(max_loc), zorder=3)\n",
        "        c_patch = ax[l_h,l_w].add_patch(el)\n",
        "        c_text = ax[l_h,l_w].text(xmin+4, ymin+15, \"%s-%0.2f\"%(class_list_short[max_loc], max_val), c=plt.cm.tab20(max_loc), fontsize=6, clip_on=True)\n",
        "        c_patch.set_path_effects([path_effects.Stroke(linewidth=width_list[index]+1.5, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "        c_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "                       path_effects.Normal()])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzQiXvJSvD6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Free the RAM before going further in the notebook\n",
        "#A RUNTIME RESTART IS ADVISED\n",
        "\n",
        "del (all_im, all_im_prop)\n"
      ],
      "metadata": {
        "id": "VVM90Hi6vGuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X8qLlpnVhDzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C - The YOLO object detector**\n",
        "(YOLO - You Only Look Once)"
      ],
      "metadata": {
        "id": "RLtKgGx6stfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1\\. Train and valid data generation**"
      ],
      "metadata": {
        "id": "ssyMWqWr2PWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/\n",
        "mkdir yolo_detector\n",
        "cd yolo_detector"
      ],
      "metadata": {
        "id": "hJGoTui1HK-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic Image augmentation and bounding box targets"
      ],
      "metadata": {
        "id": "Ydmkorgw2XUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/yolo_detector/data_gen.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import matplotlib.patheffects as path_effects\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import os\n",
        "\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "from imgaug.augmentables.batches import UnnormalizedBatch\n",
        "\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"empty\"], dtype=\"str\")\n",
        "class_list_short = np.array([\"plane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "\t\t\"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"empty\"])\n",
        "\n",
        "train_list_2012 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "train_list_2007 = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\", dtype=\"str\")\n",
        "test_list_2007  = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "\n",
        "## Data augmentation\n",
        "def init_data_gen():\n",
        "\tglobal nb_train_2012, nb_train_2007, nb_test_2007, orig_nb_images\n",
        "\tglobal nb_images_per_batch, nb_keep_val, max_nb_obj_per_image, image_size, seq_iaa\n",
        "\tglobal input_data, targets, input_val, targets_val, all_im, all_im_prop\n",
        "\n",
        "\tnb_train_2012 = 11540\n",
        "\tnb_train_2007 = 5011\n",
        "\tnb_test_2007 = 4952\n",
        "\torig_nb_images = nb_train_2012 + nb_train_2007 + nb_test_2007\n",
        "\tnb_keep_val = 1000 \n",
        "\t# Pre trained net was trained using all the 2007 test examples as validation dataset\n",
        "\t# To remain homogeneous, here we exclude all these examples and use only 1000 as validation to save some RAM\n",
        "\tnb_images_per_batch = 1000 \n",
        "\t# Pre trained net was trained using 4000, so achieving similar performance would require x4 epochs\n",
        "\tmax_nb_obj_per_image = 48\n",
        "\timage_size = 288\n",
        "\t\n",
        "\tforced_regen = False\n",
        "\t\n",
        "\tseq_iaa = iaa.Sequential([\n",
        "\t\t\tiaa.Fliplr(0.5),\n",
        "\t\t\tiaa.Flipud(0.2),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
        "\t\t\tiaa.LinearContrast((0.75, 1.5)),\n",
        "\t\t\tiaa.Sometimes(0.1, iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
        "\t\t\tiaa.Multiply((0.8,1.2), per_channel=0.2),\n",
        "\t\t\tiaa.Affine(translate_percent={\"x\": (-0.2,0.2), \"y\": (-0.2,0.2)}),\n",
        "\t\t\tiaa.Sometimes(0.5,iaa.Affine(scale={\"x\": (0.8,1.2), \"y\": (0.8,1.2)})),\n",
        "\t\t\tiaa.Sometimes(0.2,iaa.Affine(rotate=(-10,10),shear=(-6,6))),\n",
        "\t\t\tiaa.Sometimes(0.02,iaa.Grayscale(alpha=(0.0, 1.0)))\n",
        "\t\t])\n",
        "\t\n",
        "\tall_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "\tall_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "\tall_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "\tall_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "\tinput_data = np.zeros((nb_images_per_batch,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets = np.zeros((nb_images_per_batch,1+max_nb_obj_per_image*7), dtype=\"float32\")\n",
        "\n",
        "\tinput_val = np.zeros((nb_keep_val,image_size*image_size*3), dtype=\"float32\")\n",
        "\ttargets_val = np.zeros((nb_keep_val,1+max_nb_obj_per_image*7), dtype=\"float32\")\n",
        "\n",
        "## Data augmentation\n",
        "def create_train_batch(visual_w=0, visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\n",
        "\tfor i in range(0, nb_images_per_batch):\n",
        "\t\t\n",
        "\t\ti_d = np.random.randint(0,orig_nb_images - nb_test_2007)\n",
        "\t\t\n",
        "\t\tif(i_d < nb_train_2012):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2012/Annotations/\"+train_list_2012[i_d]+\".xml\")\n",
        "\t\telif(i_d < nb_train_2012+nb_train_2007):\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+train_list_2007[i_d - nb_train_2012]+\".xml\")\n",
        "\t\telse:\n",
        "\t\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[i_d - nb_train_2012 - nb_train_2007]+\".xml\")\n",
        "\t\t\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "\t\tpatch = np.copy(all_im[i_d])\n",
        "\n",
        "\t\tobj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\tnb_box = len(obj_list)\n",
        "\t\tfor obj in obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tnb_box -= 1\n",
        "\t\t\t\tcontinue\n",
        "\t\t\n",
        "\t\tbbox_list = np.zeros((nb_box,5))\n",
        "\t\t\n",
        "\t\tk = 0\n",
        "\t\tfor obj in obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\t\t\t\n",
        "\t\t\tint_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\t\t\t\n",
        "\t\t\tbbox_list[k,:] = np.array([xmin,ymin,xmax,ymax,int_class])\n",
        "\t\t\tk += 1\n",
        "\t\t\t\n",
        "\t\tbbs = BoundingBoxesOnImage.from_xyxy_array(bbox_list[:,:4], shape=patch.shape)\n",
        "\t\t\n",
        "\t\tpatch_aug, bbs_aug = seq_iaa(image=patch,bounding_boxes=bbs)\n",
        "\t\t\n",
        "\t\tfor depth in range(0,3):\n",
        "\t\t\tinput_data[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = patch_aug[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\n",
        "\t\ttargets[i,0] = nb_box\n",
        "\t\tb_pos = 0\n",
        "\t\tfor k in range(0, nb_box):\n",
        "\t\t\tl_b = bbs_aug.bounding_boxes[k]\n",
        "\t\t\txmin = l_b.x1\n",
        "\t\t\tymin = l_b.y1\n",
        "\t\t\txmax = l_b.x2\n",
        "\t\t\tymax = l_b.y2\n",
        "\t\t\t\t\n",
        "\t\t\tn_xmin = max(0, xmin)\n",
        "\t\t\tn_ymin = max(0, ymin)\n",
        "\t\t\tn_xmax = min(image_size, xmax)\n",
        "\t\t\tn_ymax = min(image_size, ymax)\n",
        "\t\t\t\n",
        "\t\t\tfrac_in = (abs(n_xmax-n_xmin)*abs(n_ymax-n_ymin))/(abs(xmax-xmin)*abs(ymax-ymin))\n",
        "\t\t\t\n",
        "\t\t\tif(frac_in < 0.35 or (frac_in < 0.5 and (abs(n_xmax-n_xmin)*abs(n_ymax-n_ymin)) < 160) or (abs(xmax-xmin)*abs(ymax-ymin) < 160)):\n",
        "\t\t\t\ttargets[i,0] -= 1\n",
        "\t\t\t\tcontinue\n",
        "\t\t\n",
        "\t\t\ttargets[i,1+b_pos*7:1+(b_pos+1)*7] = np.array([bbox_list[k,4]+1, n_xmin,n_ymin,0.0,n_xmax,n_ymax,1.0])\n",
        "\t\t\tb_pos += 1\n",
        "\n",
        "\t\t\n",
        "\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\n",
        "\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\n",
        "\t\t\tax[c_x,c_y].imshow(patch_aug)\n",
        "\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\t\n",
        "\t\t\ttarg_boxes = targets[i]\n",
        "\t\t\tfor k in range(0, int(targ_boxes[0])):\n",
        "\t\t\t\txmin = targ_boxes[1+k*7+1]\n",
        "\t\t\t\tymin = targ_boxes[1+k*7+2]\n",
        "\t\t\t\txmax = targ_boxes[1+k*7+4]\n",
        "\t\t\t\tymax = targ_boxes[1+k*7+5]\n",
        "\t\t\t\tp_c = int(targ_boxes[1+k*7+0]) - 1\n",
        "\t\t\t\n",
        "\t\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.8, ls=\"--\", fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\t\tc_patch = ax[c_x,c_y].add_patch(el)\n",
        "\t\t\t\tc_text = ax[c_x,c_y].text(xmin+4, ymin+15, \"%s\"%(class_list_short[p_c]), c=plt.cm.tab20(p_c), fontsize=6, clip_on=True)\n",
        "\t\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\t\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "\t\t\t\n",
        "\t\t\tvisual_iter += 1\n",
        "\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\treturn\n",
        "\n",
        "\treturn input_data, targets\n",
        "\n",
        "\n",
        "def create_val_batch(visual_w=0, visual_h=0):\n",
        "\tvisual_iter = 0\n",
        "\n",
        "\tfor i in range(0, nb_keep_val):\n",
        "\t\t\n",
        "\t\ti_d = nb_train_2012+nb_train_2007+nb_test_2007-nb_keep_val+i\n",
        "\n",
        "\t\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list_2007[nb_test_2007-nb_keep_val+i]+\".xml\")\n",
        "\t\troot = tree.getroot()\n",
        "\t\t\n",
        "\t\tpatch = np.copy(all_im[i_d])\n",
        "\n",
        "\t\tx_offset, y_offset, width2, height2 = all_im_prop[i_d]\n",
        "\n",
        "\t\tfor depth in range(0,3):\n",
        "\t\t\tinput_val[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = patch[:,:,depth].flatten(\"C\")/255.0\n",
        "\t\t\n",
        "\t\tk = 0\n",
        "\t\tobj_list = root.findall(\"object\", namespaces=None)\n",
        "\t\ttargets_val[i,0] = len(obj_list)\n",
        "\t\tfor obj in obj_list:\n",
        "\t\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\t\tif(diff.text == \"1\"):\n",
        "\t\t\t\ttargets_val[i,0] -= 1\n",
        "\t\t\t\tcontinue\n",
        "\t\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "\t\t\tint_class = np.where(class_list[:] == oclass.text)\n",
        "\t\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "\t\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "\t\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "\t\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\t\t\t\n",
        "\t\t\tn_xmin = max(0, xmin)\n",
        "\t\t\tn_ymin = max(0, ymin)\n",
        "\t\t\tn_xmax = min(image_size, xmax)\n",
        "\t\t\tn_ymax = min(image_size, ymax)\n",
        "\t\t\t\n",
        "\t\t\tfrac_in = (abs(n_xmax-n_xmin)*abs(n_ymax-n_ymin))/(abs(xmax-xmin)*abs(ymax-ymin))\n",
        "\t\t\t\n",
        "\t\t\tif(frac_in < 0.35 or (frac_in < 0.5 and (abs(n_xmax-n_xmin)*abs(n_ymax-n_ymin)) < 192) or (abs(xmax-xmin)*abs(ymax-ymin) < 192)):\n",
        "\t\t\t\ttargets_val[i,0] -= 1\n",
        "\t\t\t\t#print (\"Removed\", frac_in)\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\ttargets_val[i,1+k*7:1+(k+1)*7] = np.array([int_class[0][0]+1, n_xmin,n_ymin,0.0,n_xmax,n_ymax,1.0])\n",
        "\t\t\tk += 1\n",
        "\t\t\t#print (class_list[int_class])\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tif(visual_w*visual_h > 0):\n",
        "\t\t\tif(visual_iter == 0):\n",
        "\t\t\t\tfig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\t\t\t\n",
        "\t\t\tc_x = visual_iter // visual_w\n",
        "\t\t\tc_y = visual_iter % visual_w\n",
        "\t\t\t\n",
        "\t\t\tax[c_x,c_y].imshow(patch)\n",
        "\t\t\tax[c_x,c_y].axis('off')\n",
        "\t\t\t\n",
        "\t\t\ttarg_boxes = targets_val[i]\n",
        "\t\t\tfor k in range(0, int(targ_boxes[0])):\n",
        "\t\t\t\txmin = targ_boxes[1+k*7+1]\n",
        "\t\t\t\tymin = targ_boxes[1+k*7+2]\n",
        "\t\t\t\txmax = targ_boxes[1+k*7+4]\n",
        "\t\t\t\tymax = targ_boxes[1+k*7+5]\n",
        "\t\t\t\tp_c = int(targ_boxes[1+k*7+0]) - 1\n",
        "\t\t\t\n",
        "\t\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.8, ls=\"--\", fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\t\tc_patch = ax[c_x,c_y].add_patch(el)\n",
        "\t\t\t\tc_text = ax[c_x,c_y].text(xmin+4, ymin+15, \"%s\"%(class_list_short[p_c]), c=plt.cm.tab20(p_c), fontsize=6, clip_on=True)\n",
        "\t\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\t\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "\t\t\t\n",
        "\t\t\tvisual_iter += 1\n",
        "\t\t\tif(visual_iter >= visual_w*visual_h):\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\treturn\n",
        "\t\n",
        "\treturn input_val, targets_val\n",
        "\n",
        "\n",
        "def free_data_gen():\n",
        "  global all_im, all_im_prop, input_data, targets, input_val, targets_val\n",
        "  del (all_im, all_im_prop, input_data, targets, input_val, targets_val)\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "kX12wMn62mwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training image examples"
      ],
      "metadata": {
        "id": "hLRQg1BRIi0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/IRMIA_2022/yolo_detector/test_gen.py\n",
        "\n",
        "import data_gen as gn3\n",
        "\n",
        "gn3.init_data_gen()\n",
        "\n",
        "print(\"Random augmented training examples\")\n",
        "gn3.create_train_batch(4,3)\n",
        "\n",
        "print(\"\\nOrdered validation examples\")\n",
        "gn3.create_val_batch(4,3)\n",
        "\n",
        "gn3.free_data_gen()"
      ],
      "metadata": {
        "id": "i_UmT5czIh3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Might need to reload the notebook execution environment to unload previous data_gen afters changes\n",
        "%cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "%run test_gen.py"
      ],
      "metadata": {
        "id": "y9VKjBB1Iogc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2\\. Training the YOLO detector**"
      ],
      "metadata": {
        "id": "PIn_ni1dI153"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import data_gen as gn3\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = gn3.create_train_batch()\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "nb_keep_val = 1000\n",
        "# Pre trained net was trained using all the 2007 test examples as validation dataset\n",
        "# To remain homogeneous, here we exclude all these examples and use only 1000 as validation to save some RAM\n",
        "nb_images = 1000\n",
        "# Pre trained net was trained using 4000, so achieving similar performance would require x4 epochs (should also lower the decay value)\n",
        "nb_param = 0\n",
        "nb_class = 20\n",
        "\n",
        "max_nb_obj_per_image = 48\n",
        "\n",
        "im_size = 288\n",
        "nb_box = 5\n",
        "\n",
        "nb_epoch_per_augm = 2\n",
        "load_pre_trained = 0\n",
        "\n",
        "load_epoch = -1\n",
        "\n",
        "if(load_epoch == -1):\n",
        "\tfit_parts = i_ar([1, 1, 1, 1, -1])\n",
        "\tload_epoch = 6500\n",
        "\ttotal_epochs = 6500 + 10\n",
        "\tload_pre_trained = 1\n",
        "elif(load_epoch < 100):\n",
        "\t# PRE TRAINING\n",
        "\tfit_parts = i_ar([0, 1, 1, 1, -1])\n",
        "\ttotal_epochs = 100\n",
        "else:\n",
        "\t# REGULAR TRAINING\n",
        "\tfit_parts = i_ar([1, 1, 1, 1, -1])\n",
        "\ttotal_epochs = 8000\n",
        "\n",
        "# Pre trained net was trained using b_size=32, here the learning_rate value has been increased accordingly\n",
        "# The b_size value has been lowered so the network fit in memory\n",
        "cnn.init(in_dim=i_ar([im_size,im_size]), in_nb_ch=3, out_dim=1+max_nb_obj_per_image*(7+nb_param),\n",
        "\t b_size=16, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "gn3.init_data_gen()\n",
        "\n",
        "input_data, targets = gn3.create_train_batch()\n",
        "input_val, targets_val = gn3.create_val_batch()\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", nb_images, input_data[:,:], targets[:,:])\n",
        "cnn.create_dataset(\"VALID\", nb_keep_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "##### YOLO parameters tuning #####\n",
        "# Note : Using squared priors and default values for most of the\n",
        "# following parameters is sufficient to reach an mAP > 30%.\n",
        "# This specific setup was optimized to get the most out of this specific \"light\" YOLO architecture. \n",
        "\n",
        "prior_w = f_ar([24.,48.,96.,144.,256.])\n",
        "prior_h = f_ar([24.,64.,176.,80.,192.])\n",
        "\n",
        "prior_noobj_prob = f_ar([0.15,0.15,0.15,0.15,0.15])\n",
        "\n",
        "#Relative scaling of each error \"type\" : \n",
        "#[Position, Size, Probability, Objectness, Class, Ex. Param]\n",
        "error_scales = f_ar([4.0, 2.0, 1.0, 5.0, 3.0, 1.0])\n",
        "\n",
        "#Various IoU limit conditions\n",
        "#[Good but not best boxes, Prob. fit, Obj. fit, class fit, param fit] \n",
        "IoU_limits = f_ar([0.4, -0.5, -1.0, -1.0, -0.3, -0.3])\n",
        "\n",
        "slopes_and_maxes = f_ar([[1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [0.5, 1.2, -1.4],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 2.0, -0.2]])\n",
        "\n",
        "# A value of 1 might be better here if the choice of priors is appropriate \n",
        "strict_box_size = 2\n",
        "\n",
        "start_block = int(load_epoch / nb_epoch_per_augm)\n",
        "\n",
        "nb_yolo_filters = cnn.set_yolo_params(nb_box = nb_box, prior_w = prior_w, prior_h = prior_h, nb_class = nb_class, nb_param=nb_param,\n",
        "\t\t\t\tprior_noobj_prob = prior_noobj_prob, IoU_type = \"GIoU\", error_scales = error_scales,\n",
        "\t\t\t\tslopes_and_maxes = slopes_and_maxes, IoU_limits = IoU_limits, fit_parts = fit_parts, strict_box_size=strict_box_size)\n",
        "\n",
        "if(load_pre_trained):\n",
        "\tcnn.load(\"/content/IRMIA_2022/pre_trained_nets/yolo_detector_net0_s6500.dat\",6500, bin=1)\n",
        "elif(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\t# This specific architecture might be too difficult to train in a free Colab environement\n",
        "\t# Using half the number of filters for the first 5 conv layer can still provide good results with an mAP ~ 30%\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=24, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\t\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=48, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=96, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=128, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=256, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=256, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.conv(f_size=i_ar([3,3]), nb_filters=256, padding=i_ar([1,1]), activation=\"RELU\")\n",
        "\tcnn.conv(f_size=i_ar([1,1]), nb_filters=512, padding=i_ar([0,0]), activation=\"RELU\", drop_rate=0.1)\n",
        "\tcnn.conv(f_size=i_ar([1,1]), nb_filters=nb_yolo_filters, padding=i_ar([0,0]), activation=\"YOLO\")\n",
        "\n",
        "\n",
        "for batch_augm in range(start_block,int(total_epochs/nb_epoch_per_augm)): \n",
        "\t\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\t\n",
        "\tcnn.train(nb_epoch=nb_epoch_per_augm, learning_rate=0.0003, end_learning_rate=0.000, shuffle_every=0,\\\n",
        "\t\t\t momentum=0.8, decay=0.0010, save_every=50, silent=1, save_bin=1, TC_scale_factor=32.0)\n",
        "\tif(batch_augm == 0):\n",
        "\t\tcnn.perf_eval()\n",
        "\n",
        "\tt.join()\n",
        "\t\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "gn3.free_data_gen()\n",
        "del (input_data, targets, input_val, targets_val)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "rm89u2z3JDC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3\\. Post process the prediction**"
      ],
      "metadata": {
        "id": "YH7VgxzplBNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple network forward"
      ],
      "metadata": {
        "id": "afkTCgYxluHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import data_gen as gn3\n",
        "import re\n",
        "import os\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/IRMIA_2022/CIANNA/src/build/lib.linux-x86_64\")\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "nb_keep_val = 1000\n",
        "nb_param = 0\n",
        "nb_class = 20\n",
        "\n",
        "max_nb_obj_per_image = 48\n",
        "\n",
        "im_size = 288\n",
        "nb_box = 5\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([im_size,im_size]), in_nb_ch=3, out_dim=1+max_nb_obj_per_image*(7+nb_param),\n",
        "\t b_size=16, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "gn3.init_data_gen()\n",
        "\n",
        "input_val, targets_val = gn3.create_val_batch()\n",
        "\n",
        "cnn.create_dataset(\"TEST\", nb_keep_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "##### YOLO parameters tuning #####\n",
        "\n",
        "#Size priors for all possible boxes per grid. element \n",
        "#prior = f_ar([12.,16.,32.,64.,128.,192.])\n",
        "\n",
        "prior_w = f_ar([24.,48.,96.,144.,256.])\n",
        "prior_h = f_ar([24.,64.,176.,80.,192.])\n",
        "\n",
        "prior_noobj_prob = f_ar([0.15,0.15,0.15,0.15,0.15])\n",
        "\n",
        "#Relative scaling of each error \"type\" : \n",
        "#[Position, Size, Probability, Objectness, Class, Ex. Param]\n",
        "error_scales = f_ar([4.0, 2.0, 1.0, 5.0, 3.0, 1.0])\n",
        "\n",
        "#Various IoU limit conditions\n",
        "#[Good but not best boxes, Prob. fit, Obj. fit, class fit, param fit] \n",
        "IoU_limits = f_ar([0.4, -0.5, -1.0, -1.0, -0.3, -0.3])\n",
        "\n",
        "slopes_and_maxes = f_ar([[1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [0.5, 1.2, -1.4],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 4.5, -4.5],\\\n",
        "\t\t\t\t\t\t [1.0, 2.0, -0.2]])\n",
        "\t\t\t\t \n",
        "nb_yolo_filters = cnn.set_yolo_params(nb_box = nb_box, prior_w = prior_w, prior_h = prior_h, nb_class = nb_class, nb_param=nb_param,\n",
        "                                        prior_noobj_prob = prior_noobj_prob, IoU_type = \"GIoU\", error_scales = error_scales,\n",
        "                                        slopes_and_maxes = slopes_and_maxes, IoU_limits = IoU_limits, strict_box_size=1)\n",
        "\n",
        "load_epoch = -1\n",
        "if(load_epoch == -1):\n",
        "\tcnn.load(\"/content/IRMIA_2022/pre_trained_nets/yolo_detector_net0_s6500.dat\",6500, bin=1)\n",
        "\tload_epoch = 6500\n",
        "elif(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\tfiles = os.listdir(\"/content/IRMIA_2022/yolo_detector/net_save/\")\n",
        "\tpaths = [os.path.join(\"/content/IRMIA_2022/yolo_detector/net_save/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[s.]',path) if s.isdigit()]\n",
        "\tprint(r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent save : \" + path)\n",
        "\t\n",
        "\tcnn.load(path, r_load_epoch[0], bin=1)\n",
        "\n",
        "cnn.forward(no_error=1, saving=2)\n",
        "\n",
        "gn3.free_data_gen()\n",
        "del (input_val, targets_val)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "Az4AMquhlVIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading raw Network prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "1wBMwmwtmvH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import re\n",
        "import bisect\n",
        "import os\n",
        "import sys\n",
        "from numba import jit\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "test_list = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = 11540 + 5011 + 4952\n",
        "nb_keep_val = 1000\n",
        "\n",
        "image_size = 288\n",
        "nb_box = 5\n",
        "nb_class = 20\n",
        "nb_param = 0\n",
        "\n",
        "max_nb_obj_per_image = 48\n",
        "\n",
        "yolo_nb_reg = int(image_size/32)\n",
        "c_size = 32\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "load_epoch = 0\t\n",
        "if(load_epoch == 0):\n",
        "\tfiles = os.listdir(\"fwd_res/\")\n",
        "\tpaths = [os.path.join(\"fwd_res/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[_s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent prediction : \" + path)\n",
        "\t\n",
        "\tload_epoch = r_load_epoch[0]\n",
        "\n",
        "prior_w = np.array([24.,48.,96.,144.,256.])\n",
        "prior_h = np.array([24.,64.,176.,80.,192.])\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (nb_keep_val, nb_box*(8+nb_param+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def global_to_tile_coord(offset_tab, tile_coords, priors, c_size):\n",
        "\tbx = (offset_tab[0] + tile_coords[1])*c_size\n",
        "\tby = (offset_tab[1] + tile_coords[0])*c_size\n",
        "\tbw = priors[0]*np.exp(offset_tab[3])\n",
        "\tbh = priors[1]*np.exp(offset_tab[4])\n",
        "\treturn float(bx), float(by), float(bw), float(bh)\n",
        " \n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def box_extraction(c_pred, c_box, c_tile):\n",
        "  c_nb_box = 0\n",
        "  for i in range(0,yolo_nb_reg):\n",
        "    for j in range(0,yolo_nb_reg):\n",
        "      for k in range(0,nb_box):\n",
        "        offset = int(k*(8+nb_param+nb_class)) #no +1 for box prior in prediction\n",
        "        c_box[4] = c_pred[offset+6,i,j]\n",
        "        c_box[5] = c_pred[offset+7,i,j]\n",
        "        p_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "        cl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j]) \n",
        "        \n",
        "        bx, by, bw, bh = global_to_tile_coord(c_pred[offset:offset+6,i,j], \\\n",
        "                  np.array([i,j]), np.array([prior_w[k], prior_h[k]]), c_size)\n",
        "        c_box[0] = bx - bw*0.5\n",
        "        c_box[1] = by - bh*0.5\n",
        "        c_box[2] = bx + bw*0.5\n",
        "        c_box[3] = by + bh*0.5\n",
        "        \n",
        "        c_box[6] = k\n",
        "        c_box[7:] = c_pred[offset+8:offset+8+nb_param+nb_class,i,j]\n",
        "        c_tile[c_nb_box,:] = c_box[:]\n",
        "        c_nb_box +=1\n",
        "  return c_nb_box\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "for l in range(0,nb_keep_val):\n",
        "\tc_tile[:,:] = 0.0\n",
        "\tc_tile_kept[:,:] = 0.0\n",
        "\n",
        "\tc_pred = predict[l,:,:,:]\n",
        "\tc_nb_box = box_extraction(c_pred, c_box, c_tile_kept)\t\t\t\n",
        "\tfinal_boxes.append(np.copy(c_tile_kept[0:c_nb_box]))\n"
      ],
      "metadata": {
        "id": "riuGbZzom9CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display raw prediction of the YOLO network (all boxes)"
      ],
      "metadata": {
        "id": "xCwlaZBhCNyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_d = 0\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5), dpi=160, constrained_layout=True)\n",
        "\n",
        "c_data = all_im[nb_train_2007 + nb_train_2012 + nb_test_2007 - nb_keep_val + i_d]/255.0\n",
        "ax.imshow(c_data)\n",
        "ax.axis('off')\n",
        "\n",
        "im_boxes = final_boxes[i_d]\n",
        "\n",
        "for k in range(0, np.shape(im_boxes)[0]):\n",
        "\t\t\txmin = max(-0.5,(im_boxes[k,0]) - 0.5)\n",
        "\t\t\tymin = max(-0.5,(im_boxes[k,1]) - 0.5)\n",
        "\t\t\txmax = min(image_size-0.5,(im_boxes[k,2]) - 0.5)\n",
        "\t\t\tymax = min(image_size-0.5,(im_boxes[k,3]) - 0.5)\n",
        "\t\t\t\n",
        "\t\t\tp_c = np.argmax(im_boxes[k,7:])\n",
        "\t\t\t\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=2.0*im_boxes[k,5]+0.5, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\tax.add_patch(el)\n",
        "   \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sM3Z6Yk-CMGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Objectness filtering"
      ],
      "metadata": {
        "id": "PNY-E9wdE5hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def box_filter(c_pred, c_box, c_tile, obj_limit, class_limit):\n",
        "  c_nb_box = 0\n",
        "  for i in range(0,yolo_nb_reg):\n",
        "    for j in range(0,yolo_nb_reg):\n",
        "      for k in range(0,nb_box):\n",
        "        offset = int(k*(8+nb_param+nb_class)) #no +1 for box prior in prediction\n",
        "        c_box[4] = c_pred[offset+6,i,j]\n",
        "        c_box[5] = c_pred[offset+7,i,j]\n",
        "        p_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "        cl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j]) \n",
        "        \n",
        "        if(c_box[5] >= obj_limit and p_c > class_limit):\n",
        "          bx, by, bw, bh = global_to_tile_coord(c_pred[offset:offset+6,i,j], \\\n",
        "                    np.array([i,j]), np.array([prior_w[k], prior_h[k]]), c_size)\n",
        "          c_box[0] = max(0,bx - bw*0.5 - 1)\n",
        "          c_box[1] = max(0,by - bh*0.5 - 1)\n",
        "          c_box[2] = min(image_size,bx + bw*0.5 + 1)\n",
        "          c_box[3] = min(image_size,by + bh*0.5 + 1)\n",
        "          \n",
        "          c_box[6] = k\n",
        "          c_box[7:] = c_pred[offset+8:offset+8+nb_param+nb_class,i,j]\n",
        "          c_tile[c_nb_box,:] = c_box[:]\n",
        "          c_nb_box +=1\n",
        "  return c_nb_box\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "obj_limit = 0.3\n",
        "class_limit = 0.6\n",
        "\n",
        "for l in range(0,nb_keep_val):\n",
        "\tc_tile[:,:] = 0.0\n",
        "\tc_tile_kept[:,:] = 0.0\n",
        "\n",
        "\tc_pred = predict[l,:,:,:]\n",
        "\tc_nb_box = box_filter(c_pred, c_box, c_tile_kept, obj_limit, class_limit)\n",
        "\tfinal_boxes.append(np.copy(c_tile_kept[0:c_nb_box]))"
      ],
      "metadata": {
        "id": "ggaJAUUJFXkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i_d = 0\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5), dpi=160, constrained_layout=True)\n",
        "\n",
        "c_data = all_im[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i_d]/255.0\n",
        "ax.imshow(c_data)\n",
        "ax.axis('off')\n",
        "\n",
        "im_boxes = final_boxes[i_d]\n",
        "\n",
        "for k in range(0, np.shape(im_boxes)[0]):\n",
        "  xmin = max(-0.5,(im_boxes[k,0]) - 0.5)\n",
        "  ymin = max(-0.5,(im_boxes[k,1]) - 0.5)\n",
        "  xmax = min(image_size-0.5,(im_boxes[k,2]) - 0.5)\n",
        "  ymax = min(image_size-0.5,(im_boxes[k,3]) - 0.5)\n",
        "  \n",
        "  p_c = np.argmax(im_boxes[k,7:])\n",
        "  \n",
        "  el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=2.0*im_boxes[k,5]+0.5, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "  ax.add_patch(el)\n",
        "  ax.text(xmin+2, ymin-3, \"%s:%0.2f-%0.2f\"%(class_list_short[p_c],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=9,clip_on=True)\n",
        "   \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LDaIPIBCF_-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Non-Max suppression"
      ],
      "metadata": {
        "id": "21jGbwuqIKIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\tenclose_w = (max(box1[2], box2[2]) - min(box1[0], box2[0]))\n",
        "\tenclose_h = (max(box1[3], box2[3]) - min(box1[1],box2[1]))\n",
        "\tenclose_2d = enclose_w*enclose_h\n",
        "\n",
        "\tcx_a = (box1[2] + box1[0])*0.5; cx_b = (box2[2] + box2[0])*0.5\n",
        "\tcy_a = (box1[3] + box1[1])*0.5; cy_b = (box2[3] + box2[1])*0.5\n",
        "\tdist_cent = np.sqrt((cx_a - cx_b)*(cx_a - cx_b) + (cy_a - cy_b)*(cy_a - cy_b))\n",
        "\tdiag_enclose = np.sqrt(enclose_w*enclose_w + enclose_h*enclose_h)\n",
        "\n",
        "  # DIoU\n",
        "\t#return float(inter_2d)/float(uni_2d) - float(dist_cent)/float(diag_enclose)\n",
        "  # GIoU\n",
        "\treturn float(inter_2d)/float(uni_2d) - float(enclose_2d - uni_2d)/float(enclose_2d)\n",
        "\t\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_classical_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\n",
        "\treturn float(inter_2d)/float(uni_2d)\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold):\n",
        "  c_nb_box_final = 0\n",
        "  is_match = 1\n",
        "  c_box_size_prev = c_nb_box\n",
        "\n",
        "  while(c_nb_box > 0):\n",
        "    max_objct = np.argmax(c_tile[:c_box_size_prev,5])\n",
        "    c_box = np.copy(c_tile[max_objct])\n",
        "    c_tile[max_objct,4] = 0.0\n",
        "    c_tile_kept[c_nb_box_final] = c_box\n",
        "    c_nb_box_final += 1\n",
        "    c_nb_box -= 1\n",
        "    i = 0\n",
        "    for i in range(0,c_box_size_prev):\n",
        "      if(c_tile[i,5] < 0.0000001):\n",
        "        continue\n",
        "      IoU = fct_IoU(c_box[:4], c_tile[i,:4])\n",
        "      if(IoU > nms_threshold):\n",
        "        c_tile[i] = 0.0\n",
        "        c_nb_box -= 1\n",
        "     \n",
        "  return c_nb_box_final\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "obj_limit = 0.3\n",
        "class_limit = 0.5\n",
        "\n",
        "nms_threshold = 0.3 #here using GIoU in the interval [-1,1]\n",
        "#lower value is more strict\n",
        "\n",
        "for l in range(0,nb_keep_val):\n",
        "  c_tile[:,:] = 0.0\n",
        "  c_tile_kept[:,:] = 0.0\n",
        "\n",
        "  c_pred = predict[l,:,:,:]\n",
        "  c_nb_box = box_filter(c_pred, c_box, c_tile, obj_limit, class_limit)\n",
        "\n",
        "  c_nb_box_final = c_nb_box\n",
        "  c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold)\n",
        "  final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n"
      ],
      "metadata": {
        "id": "N3Aj2yw2_hWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5), dpi=210, constrained_layout=True)\n",
        "\n",
        "c_data = all_im[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i_d]/255.0\n",
        "ax.imshow(c_data)\n",
        "ax.axis('off')\n",
        "\n",
        "im_boxes = final_boxes[i_d]\n",
        "\n",
        "for k in range(0, np.shape(im_boxes)[0]):\n",
        "  xmin = max(-0.5,(im_boxes[k,0]) - 0.5)\n",
        "  ymin = max(-0.5,(im_boxes[k,1]) - 0.5)\n",
        "  xmax = min(image_size-0.5,(im_boxes[k,2]) - 0.5)\n",
        "  ymax = min(image_size-0.5,(im_boxes[k,3]) - 0.5)\n",
        "  \n",
        "  p_c = np.argmax(im_boxes[k,7:])\n",
        "  \n",
        "  el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=1.5, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "  c_patch = ax.add_patch(el)\n",
        "  c_text = ax.text(xmin+2, ymin-3, \"%s:%0.2f-%0.2f\"%(class_list_short[p_c],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=9,clip_on=True)\n",
        "  c_patch.set_path_effects([path_effects.Stroke(linewidth=2.5, foreground='black'),\n",
        "                        path_effects.Normal()])\n",
        "  c_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "                        path_effects.Normal()])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tkbEM7agKXWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the target boxes"
      ],
      "metadata": {
        "id": "gfEXv1fLMnr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.zeros((nb_keep_val,1+max_nb_obj_per_image*7), dtype=\"float32\")\n",
        "\n",
        "class_count = np.zeros((nb_class))\n",
        "\n",
        "for i in tqdm(range(0, nb_keep_val)):\n",
        "\t\n",
        "\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list[nb_test_2007 - nb_keep_val + i]+\".xml\")\n",
        "\troot = tree.getroot()\n",
        "\t\n",
        "\tx_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images - nb_keep_val + i]\n",
        "\t\n",
        "\tk = 0\n",
        "\tobj_list = root.findall(\"object\", namespaces=None)\n",
        "\ttargets[i,0] = len(obj_list)\n",
        "\tfor obj in obj_list:\n",
        "\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\tif(diff.text == \"1\"):\n",
        "\t\t\ttargets[i,0] -= 1\n",
        "\t\t\tcontinue\n",
        "\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "\t\tint_class = np.where(class_list[:] == oclass.text)\n",
        "\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\n",
        "\t\ttargets[i,1+k*7:1+(k+1)*7] = np.array([int_class[0][0]+1, xmin,ymin,0.0,xmax,ymax,1.0])\n",
        "\t\tclass_count[int_class[0][0]] += 1\n",
        "\t\t\n",
        "\t\tk += 1\n"
      ],
      "metadata": {
        "id": "nSrEH4XIMmLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_start = 0\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(1.5*nb_w,1.5*nb_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for i in range(0, nb_h):\n",
        "\tfor j in range(0, nb_w):\n",
        "\t\ti_d = i*nb_w + j + id_start\n",
        "\t\t\n",
        "\t\tc_data = all_im[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i_d]/255.0\n",
        "\t\tax[i,j].imshow(c_data)\n",
        "\t\tax[i,j].axis('off')\n",
        "\t\t\n",
        "\t\tim_boxes = final_boxes[i_d]\n",
        "\t\t\n",
        "\t\ttarg_boxes = targets[i_d]\n",
        "\t\tfor k in range(0, int(targ_boxes[0])):\n",
        "\t\t\txmin = (targ_boxes[1+k*7+1])\n",
        "\t\t\tymin = (targ_boxes[1+k*7+2])\n",
        "\t\t\txmax = (targ_boxes[1+k*7+4])\n",
        "\t\t\tymax = (targ_boxes[1+k*7+5])\n",
        "\t\t\tp_c = int(targ_boxes[1+k*7+0]) - 1\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=1.0, ls=\"--\", fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\tc_patch = ax[i,j].add_patch(el)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "\t\tfor k in range(0, np.shape(im_boxes)[0]):\n",
        "\t\t\txmin = max(-0.5,(im_boxes[k,0]) - 0.5)\n",
        "\t\t\tymin = max(-0.5,(im_boxes[k,1]) - 0.5)\n",
        "\t\t\txmax = min(image_size-0.5,(im_boxes[k,2]) - 0.5)\n",
        "\t\t\tymax = min(image_size-0.5,(im_boxes[k,3]) - 0.5)\n",
        "\t\t\t\n",
        "\t\t\tp_c = np.argmax(im_boxes[k,7:])\n",
        "\t\t\t\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=1.0, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\tc_patch = ax[i,j].add_patch(el)\n",
        "\t\t\tc_text = ax[i,j].text(xmin+5, ymin+18, \"%s:%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=4,clip_on=True)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qy6mOjFmMCTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4\\. Performance metric with mAP**\n",
        "\n",
        "When measuring AP performance, the objectness (or any other sensitvity) threshold must be low,\n",
        "since the metric actually integrate over all the confidence interval."
      ],
      "metadata": {
        "id": "1zul5j3SUr8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "# The mAP metric integrate the sensitivity of the network over the full range of objectness,\n",
        "# therefore the obj_limit can be very low to sample the low objectness part of the AP curves\n",
        "# without lowering the end mAP score (still non zero to save up computation time).\n",
        "# \n",
        "\n",
        "obj_limit = 0.05\n",
        "class_limit = 0.4\n",
        "\n",
        "nms_threshold = 0.2 #here using DIoU in the interval [-1,1]\n",
        "#lower value is more strict\n",
        "\n",
        "AP_IoU_val = 0.5\n",
        "\n",
        "for l in range(0,nb_keep_val):\n",
        "  c_tile[:,:] = 0.0\n",
        "  c_tile_kept[:,:] = 0.0\n",
        "\n",
        "  c_pred = predict[l,:,:,:]\n",
        "  c_nb_box = box_filter(c_pred, c_box, c_tile, obj_limit, class_limit)\n",
        "\n",
        "  c_nb_box_final = c_nb_box\n",
        "  c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold)\n",
        "  final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "\n",
        "recall_precision = np.empty((nb_keep_val), dtype=\"object\")\n",
        "\n",
        "print(\"Find associations ...\", flush=True)\n",
        "\n",
        "for i_d in tqdm(range(0, nb_keep_val)):\n",
        "\t\t\t\t\n",
        "\trecall_precision[i_d] = np.zeros((np.shape(final_boxes[i_d])[0], 6))\n",
        "\t\n",
        "\tif(np.shape(final_boxes[i_d])[0] == 0):\n",
        "\t\tcontinue\n",
        "\t\n",
        "\trecall_precision[i_d][:,0] = np.amax(final_boxes[i_d][:,7:], axis=1)\n",
        "\trecall_precision[i_d][:,1] = final_boxes[i_d][:,5]\n",
        "\t\n",
        "\trecall_precision[i_d][:,5] = np.argmax(final_boxes[i_d][:,7:], axis=1)\n",
        "\t\n",
        "\tkept_boxes = targets[i_d]\n",
        "\t\n",
        "\tIoU_table = np.zeros((int(kept_boxes[0]),np.shape(final_boxes[i_d])[0])) - 1.0\n",
        "\t\n",
        "\tfor i in range(0,int(kept_boxes[0])):\n",
        "\t\tfor j in range(0,np.shape(final_boxes[i_d])[0]):\n",
        "\t\t\txmin = (kept_boxes[1+i*7+1])\n",
        "\t\t\tymin = (kept_boxes[1+i*7+2])\n",
        "\t\t\txmax = (kept_boxes[1+i*7+4])\n",
        "\t\t\tymax = (kept_boxes[1+i*7+5])\n",
        "\t\t\tc_kept_box = np.array([xmin, ymin, xmax, ymax])\n",
        "\t\t\tIoU_table[i,j] = fct_classical_IoU(c_kept_box, final_boxes[i_d][j,:4])\n",
        "\t\t\t\n",
        "\t# Loop over the true boxes to find best prediction associated\n",
        "\tfor i in range(0,int(kept_boxes[0])):\n",
        "\t\tbest_match_id = np.unravel_index(np.argmax(IoU_table),np.shape(IoU_table))\n",
        "\t\t\n",
        "\t\tbest_match_IoU = IoU_table[best_match_id]\n",
        "\t\t\n",
        "\t\tIoU_table[best_match_id[0],:] = -1.0\n",
        "\t\t\n",
        "\t\tif (best_match_IoU >= AP_IoU_val and np.argmax(final_boxes[i_d][best_match_id[1],7:]) == int(kept_boxes[1+best_match_id[0]*7+0]-1)):\n",
        "\t\t#if(c_IoU >= AP_IoU_val):\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],2] = 1\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],3] = best_match_id[1]\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],4] = best_match_IoU\n",
        "\t\t\tIoU_table[:,best_match_id[1]] = -1.0\n",
        "\t\t\n",
        "\n",
        "print(\"Process and flatten the mAP result\")\n",
        "flatten = np.vstack(recall_precision.flatten())\n",
        "\n",
        "recall_precision_f = np.zeros((np.shape(flatten)[0], 10))\n",
        "recall_precision_f[:,:6] = flatten[:,:]\n",
        "\n",
        "recall_precision_fs = (recall_precision_f[(recall_precision_f[:,1]*recall_precision_f[:,0]).argsort()])[::-1]\n",
        "\n",
        "recall_precision_fs[:,6] = np.cumsum(recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,7] = np.cumsum(1.0 - recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,8] = recall_precision_fs[:,6] / (recall_precision_fs[:,6]+recall_precision_fs[:,7])\n",
        "recall_precision_fs[:,9] = recall_precision_fs[:,6] / np.sum(class_count)\n",
        "\n",
        "\n",
        "interp_curve = np.zeros((np.shape(recall_precision_fs)[0],2))\n",
        "\n",
        "interp_curve[:,0] = recall_precision_fs[:,9]\n",
        "#Go in reverse to set the value for the all point interpolation\n",
        "c_max_val = np.min(recall_precision_fs[:,8])\n",
        "for i in range(0, np.shape(recall_precision_fs)[0]):\n",
        "    i_d = np.shape(recall_precision_fs)[0] - i - 1\n",
        "    if(recall_precision_fs[i_d,8] > c_max_val):\n",
        "        c_max_val = recall_precision_fs[i_d,8]\n",
        "    interp_curve[i_d,1] = c_max_val\n",
        "    \n",
        "\n",
        "AP_all = np.trapz(interp_curve[:,1], interp_curve[:,0])\n",
        "print (\"AP_all (%.2f): %f%%\"%(AP_IoU_val, AP_all*100.0))\n",
        "\n",
        "    \n",
        "plt.figure(figsize=(4*1.0,3*1.0), dpi=200, constrained_layout=True)\n",
        "plt.plot(recall_precision_fs[:,9], recall_precision_fs[:,8])\n",
        "plt.plot(interp_curve[:,0], interp_curve[:,1], label=\"New\")\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "plt.title(\"All classes as one AP curve\", fontsize=8)\n",
        "\n",
        "#print (class_count)\n",
        "sumAP = 0\n",
        "print (\"**** Per class AP ****\")\n",
        "fig, ax = plt.subplots(figsize=(4*1.3,3*1.3), dpi=200, constrained_layout=True)\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "for k in range(0, nb_class):\n",
        "\tindex = np.where(recall_precision_fs[:,5] == k)\n",
        "\tl_recall_precision_fs = recall_precision_fs[index[0]]\n",
        "\tl_recall_precision_fs[:,6] = np.cumsum(l_recall_precision_fs[:,2])\n",
        "\tl_recall_precision_fs[:,7] = np.cumsum(1.0 - l_recall_precision_fs[:,2])\n",
        "\tl_recall_precision_fs[:,8] = l_recall_precision_fs[:,6] / (l_recall_precision_fs[:,6]+l_recall_precision_fs[:,7])\n",
        "\tl_recall_precision_fs[:,9] = l_recall_precision_fs[:,6] / class_count[k]\n",
        "\t\n",
        "\tinterp_curve = np.zeros((np.shape(index[0])[0],2))\n",
        "\n",
        "\tinterp_curve[:,0] = l_recall_precision_fs[:,9]\n",
        "\t#Go in reverse to set the value for the all point interpolation\n",
        "\tc_max_val = np.min(l_recall_precision_fs[:,8])\n",
        "\tfor i in range(0, np.shape(l_recall_precision_fs)[0]):\n",
        "\t\ti_d = np.shape(l_recall_precision_fs)[0] - i - 1\n",
        "\t\tif(l_recall_precision_fs[i_d,8] > c_max_val):\n",
        "\t\t\tc_max_val = l_recall_precision_fs[i_d,8]\n",
        "\t\tinterp_curve[i_d,1] = c_max_val\n",
        "\t\n",
        "\tAP = np.trapz(interp_curve[:,1], interp_curve[:,0])\n",
        "\tsumAP += AP\n",
        "\t\n",
        "\tplt.plot(interp_curve[:,0], interp_curve[:,1], label=class_list_short[k],c=plt.cm.tab20(k))\n",
        "\t#plt.plot(l_recall_precision_fs[:,9], l_recall_precision_fs[:,8], label=class_list[k], c=plt.cm.tab20(k))\n",
        "\t\n",
        "\tprint(\"AP %-8s: %5.2f%%     Total: %4d - T: %4d - F: %4d\"%(class_list_short[k], AP*100.0, class_count[k], l_recall_precision_fs[-1,6], l_recall_precision_fs[-1,7]))\n",
        "plt.legend(bbox_to_anchor=(1.02,0.98), fontsize=8)\n",
        "plt.title(\"Per class AP curve\", fontsize=8)\n",
        "\n",
        "print (\"\\n**** mAP (%.2f): %f%% ****\"%(AP_IoU_val, sumAP/nb_class*100.0))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xyp3FcZzUx9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A runtime restart is advised before going to section 6"
      ],
      "metadata": {
        "id": "2-Ft1-BEqD9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5\\. Practical work**\n",
        "\n",
        "**How to improve the detection result ?**\n",
        "\n",
        "---\n",
        "**1. Improve the prediction post-process**  \n",
        "**Note:** *The present \"post-school\" version of the notebook includes an optimized post-process in a new section 6*\n",
        "\n",
        "\n",
        "  *   Use a more complex object filtering\n",
        "      *   CIANNA predicts separate Probability, Objectness, and class score  \n",
        "        \n",
        "          The current selection is based on [Prob x Obj.]  \n",
        "          -- Try [Prob x Obj. x Class] instead  \n",
        "          -- Try defining different thresholds for each of them\n",
        "      *   The previous elements are both box and class dependant  \n",
        "\n",
        "          Single values selection can be replaced by lists of values corresponding to each box/class  \n",
        "          -- Try having a different Probability / Objectness threshold for each box size prior  \n",
        "          -- Try having different class score threshold for each class. Update the class association for the boxes (e.g.put to zero class scores below the selected threshold before selecting the class)  \n",
        "          -- Advanced: try having a list of Probability / Objectness / Class score thresholds for each box prior\n",
        "\n",
        "  *   Have a more advanced NMS  \n",
        "      -- Try different types of IoU for NMS (Classical, GIoU, DIoU, CIoU)  \n",
        "      -- Try having different IoU threshold for boxes of the same class and boxes of a different class\n",
        "      -- For the two previous cases, try having a different IoU threshold depending on the quality of the prediction (Try Prob. only at first, and then any combination of Prob. / Obj. / class)  \n",
        "      -- As before, these values might also be different for each box prior (e.g being more strict if boxes from large size priors overlap than for smaller size priors)   \n",
        "\n",
        "  *   Try MC dropout prediction  \n",
        "      -- Choose what to do with the output list for each box element (pos, size, Prob., Obj., class.). E.g., average, percentile, keep maximum, keep minimum, etc.  \n",
        "      -- Try computing the STD of the prediction on some output parts (e.g. Prob.) and use them as new filtering criteria  \n",
        "---\n",
        "**2. Improve the network itself**  \n",
        "**Note:** *The following suggestions are already included in the present \"post-school\" notebook version. Still, the choice of parameters and priors might remain suboptimal, and one can still explore how changing these parameters affect the training results.**\n",
        "\n",
        "Most suggested changes would work better on a new training from scratch. Still, continuing the training from the pre-trained network might be possible for some of them.\n",
        "  *   Change the number of box size priors or their sizes  \n",
        "      More box priors would help in crowded areas. It might also be useful to have less distance between two size priors.  \n",
        "      BUT training is more difficult with a lot of box priors. Each box prior is optimized independently of the others, so they actually \"share\" the list of training examples. This might produce poorly constrained boxes or even cause unstable training! Splitting the box size space in non-square priors might be a better way to distribute the objects over the independent box priors.\n",
        "  * Have a different \"no object\" scaling for each size-prior to better follow the target object size distribution  \n",
        "  * Rebalance the loss by applying a different scaling to each element  \n",
        "  * Adjust some IoU limits, mainly the \"Good but not best association\" limit, but also the limits for probability, objectness and classification inclusion (cascading loss).\n",
        "  * Change the output activation function parameters. For example, choosing a greater slope for the classification should reduce the number of epochs required while getting closer to a binary behavior.\n",
        "  * Finally, play on the network architecture. Note that there is a strong interplay between all the previous parameters and the selected architecture.  \n",
        "    -- Try increasing the input size  \n",
        "    -- Try changing the output grid size (either from the input size or by changing the spatial reduction factor)  \n",
        "    -- Try replacing the pooling layers with stride 2 convolution filters  \n",
        "    -- Play with the network depth and number of filters in the various layers  \n",
        "---\n",
        "**3. Improve the training dataset**\n",
        "  * The present training dataset is strongly imbalanced. Achieving real balance would be difficult (and most probably not very efficient) dueto the fact that there are several objects of differenc class per image. Still, adding a scaling to each class Loss or to the probability of drawing a random image depending on the contained objects could strongly improve the results if done carefully.\n",
        "  * Some training images are un-necessarily confusing either due to the image themself or their labeling. Removing such \"outliers\" (either the image, or the target box) might in fact improve the overall detection. It is also possible to play on the objects determined as difficult depending on the context, or to filter too small, or too overlapping boxes.\n",
        "  * Finally, it is common to pre-train a detection network as a classifier at first since large datasets like **ImageNet** are available for such task. After training the classifier, the last few layers are removed and replaced by the last layers of a detection network before further training. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S1xGjtOnRPuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6\\. Proposed post-process optimization (Post-School update)**\n"
      ],
      "metadata": {
        "id": "XCPUpKGSjt2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visually appealing\n"
      ],
      "metadata": {
        "id": "XzInUIcRu26v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import re\n",
        "import bisect\n",
        "import os\n",
        "import sys\n",
        "from numba import jit\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "test_list = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = 11540 + 5011 + 4952\n",
        "nb_keep_val = 1000\n",
        "\n",
        "image_size = 288\n",
        "nb_box = 5\n",
        "nb_class = 20\n",
        "nb_param = 0\n",
        "\n",
        "max_nb_obj_per_image = 48\n",
        "\n",
        "yolo_nb_reg = int(image_size/32)\n",
        "c_size = 32\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "load_epoch = 0\t\n",
        "if(load_epoch == 0):\n",
        "\tfiles = os.listdir(\"fwd_res/\")\n",
        "\tpaths = [os.path.join(\"fwd_res/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[_s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent prediction : \" + path)\n",
        "\t\n",
        "\tload_epoch = r_load_epoch[0]\n",
        "\n",
        "prior_w = np.array([24.,48.,96.,144.,256.])\n",
        "prior_h = np.array([24.,64.,176.,80.,192.])\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (nb_keep_val, nb_box*(8+nb_param+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def global_to_tile_coord(offset_tab, tile_coords, priors, c_size):\n",
        "\tbx = (offset_tab[0] + tile_coords[1])*c_size\n",
        "\tby = (offset_tab[1] + tile_coords[0])*c_size\n",
        "\tbw = priors[0]*np.exp(offset_tab[3])\n",
        "\tbh = priors[1]*np.exp(offset_tab[4])\n",
        "\treturn float(bx), float(by), float(bw), float(bh)\n",
        " \n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def box_extraction(c_pred, c_box, c_tile, prob_obj_cases, class_soft_limit):\n",
        "  c_nb_box = 0\n",
        "  for i in range(0,yolo_nb_reg):\n",
        "    for j in range(0,yolo_nb_reg):\n",
        "      for k in range(0,nb_box):\n",
        "        offset = int(k*(8+nb_param+nb_class)) #no +1 for box prior in prediction\n",
        "        c_box[4] = c_pred[offset+6,i,j]\n",
        "        c_box[5] = c_pred[offset+7,i,j]\n",
        "        p_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "        cl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j]) \n",
        "        \n",
        "        if(c_box[5]*p_c >= prob_obj_cases[k] and p_c > class_soft_limit[0]):\n",
        "          bx, by, bw, bh = global_to_tile_coord(c_pred[offset:offset+6,i,j], \\\n",
        "                    np.array([i,j]), np.array([prior_w[k], prior_h[k]]), c_size)\n",
        "          c_box[0] = max(0,bx - bw*0.5 - 1)\n",
        "          c_box[1] = max(0,by - bh*0.5 - 1)\n",
        "          c_box[2] = min(image_size,bx + bw*0.5 + 1)\n",
        "          c_box[3] = min(image_size,by + bh*0.5 + 1)\n",
        "          \n",
        "          c_box[6] = k\n",
        "          c_box[7:] = c_pred[offset+8:offset+8+nb_param+nb_class,i,j]\n",
        "          c_tile[c_nb_box,:] = c_box[:]\n",
        "          c_nb_box +=1\n",
        "\n",
        "  return c_nb_box\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\tenclose_w = (max(box1[2], box2[2]) - min(box1[0], box2[0]))\n",
        "\tenclose_h = (max(box1[3], box2[3]) - min(box1[1],box2[1]))\n",
        "\tenclose_2d = enclose_w*enclose_h\n",
        "\n",
        "\tcx_a = (box1[2] + box1[0])*0.5; cx_b = (box2[2] + box2[0])*0.5\n",
        "\tcy_a = (box1[3] + box1[1])*0.5; cy_b = (box2[3] + box2[1])*0.5\n",
        "\tdist_cent = np.sqrt((cx_a - cx_b)*(cx_a - cx_b) + (cy_a - cy_b)*(cy_a - cy_b))\n",
        "\tdiag_enclose = np.sqrt(enclose_w*enclose_w + enclose_h*enclose_h)\n",
        "\n",
        "  # DIoU\n",
        "\t#return float(inter_2d)/float(uni_2d) - float(dist_cent)/float(diag_enclose)\n",
        "  # GIoU\n",
        "\treturn float(inter_2d)/float(uni_2d) - float(enclose_2d - uni_2d)/float(enclose_2d)\n",
        "\t\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_classical_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\n",
        "\treturn float(inter_2d)/float(uni_2d)\n",
        "\n",
        "#@jit(nopython=True, cache=True, fastmath=False)\n",
        "def apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold):\n",
        "  c_nb_box_final = 0\n",
        "  is_match = 1\n",
        "  c_box_size_prev = c_nb_box\n",
        "\n",
        "  while(c_nb_box > 0):\n",
        "    max_objct = np.argmax(c_tile[:c_box_size_prev,5]*np.amax(c_tile[:c_box_size_prev,7:], axis=1))\n",
        "    c_box = np.copy(c_tile[max_objct])\n",
        "    c_tile[max_objct,5] = 0.0\n",
        "    c_tile_kept[c_nb_box_final] = c_box\n",
        "    c_nb_box_final += 1\n",
        "    c_nb_box -= 1\n",
        "    i = 0\n",
        "    \n",
        "    for i in range(0,c_box_size_prev):\n",
        "      if(c_tile[i,5] < 0.00000001):\n",
        "        continue\n",
        "      IoU = fct_IoU(c_box[:4], c_tile[i,:4])\n",
        "      c_score = c_tile[i,5]*np.max(c_tile[i,7:])\n",
        "      \n",
        "      if((IoU > 0.2 and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]) and c_score >= 0.9)\n",
        "        or (IoU > 0.2 and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]) and c_score < 0.9 and c_score >= 0.1)\n",
        "        or (IoU > 0.5 and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]) and c_score >= 0.9)\n",
        "        or (IoU > 0.3 and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]) and c_score < 0.9 and c_score >= 0.1)\n",
        "        or (IoU > -0.6 and c_score < 0.1)):\n",
        "        c_tile[i] = 0.0\n",
        "        c_nb_box -= 1\n",
        "     \n",
        "  return c_nb_box_final\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "#Choice of filters that produce visually appealing results (!= best mAP )\n",
        "obj_threshold = 6*np.array([0.1,0.1,0.1,0.1,0.1])\n",
        "class_soft_limit = np.array([0.7])\n",
        "\n",
        "nms_threshold = 0.1\n",
        "#Not used here, context dependant thresholds are defined in the NMS fct\n",
        "\n",
        "for l in tqdm(range(0,nb_keep_val)):\n",
        "\tc_tile[:,:] = 0.0\n",
        "\tc_tile_kept[:,:] = 0.0\n",
        "\n",
        "\tc_pred = predict[l,:,:,:]\n",
        "\tc_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\t\t\t\n",
        "\n",
        "\tc_nb_box_final = c_nb_box\n",
        "\tc_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold)\n",
        "\tfinal_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n"
      ],
      "metadata": {
        "id": "puyd6fxom1l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.zeros((nb_keep_val,1+max_nb_obj_per_image*7), dtype=\"float32\")\n",
        "\n",
        "class_count = np.zeros((nb_class))\n",
        "\n",
        "for i in tqdm(range(0, nb_keep_val)):\n",
        "\t\n",
        "\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list[nb_test_2007 - nb_keep_val + i]+\".xml\")\n",
        "\troot = tree.getroot()\n",
        "\t\n",
        "\tx_offset, y_offset, width2, height2 = all_im_prop[orig_nb_images - nb_keep_val + i]\n",
        "\t\n",
        "\tk = 0\n",
        "\tobj_list = root.findall(\"object\", namespaces=None)\n",
        "\ttargets[i,0] = len(obj_list)\n",
        "\tfor obj in obj_list:\n",
        "\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\tif(diff.text == \"1\"):\n",
        "\t\t\ttargets[i,0] -= 1\n",
        "\t\t\tcontinue\n",
        "\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "\t\tint_class = np.where(class_list[:] == oclass.text)\n",
        "\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\n",
        "\t\ttargets[i,1+k*7:1+(k+1)*7] = np.array([int_class[0][0]+1, xmin,ymin,0.0,xmax,ymax,1.0])\n",
        "\t\tclass_count[int_class[0][0]] += 1\n",
        "\t\t\n",
        "\t\tk += 1\n"
      ],
      "metadata": {
        "id": "_LhrQUzroNHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_start = 0\n",
        "\n",
        "nb_w = 4\n",
        "nb_h = 8\n",
        "\n",
        "fig, ax = plt.subplots(nb_h, nb_w, figsize=(1.5*nb_w,1.5*nb_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for i in range(0, nb_h):\n",
        "\tfor j in range(0, nb_w):\n",
        "\t\ti_d = i*nb_w + j + id_start\n",
        "\t\t\n",
        "\t\tc_data = all_im[nb_train_2007 + nb_test_2007 + nb_train_2012 - nb_keep_val + i_d]/255.0\n",
        "\t\tax[i,j].imshow(c_data)\n",
        "\t\tax[i,j].axis('off')\n",
        "\t\t\n",
        "\t\tim_boxes = final_boxes[i_d]\n",
        "\t\t\n",
        "\t\ttarg_boxes = targets[i_d]\n",
        "\t\tfor k in range(0, int(targ_boxes[0])):\n",
        "\t\t\txmin = (targ_boxes[1+k*7+1])\n",
        "\t\t\tymin = (targ_boxes[1+k*7+2])\n",
        "\t\t\txmax = (targ_boxes[1+k*7+4])\n",
        "\t\t\tymax = (targ_boxes[1+k*7+5])\n",
        "\t\t\tp_c = int(targ_boxes[1+k*7+0]) - 1\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=1.0, ls=\"--\", fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\tc_patch = ax[i,j].add_patch(el)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "\t\tfor k in range(0, np.shape(im_boxes)[0]):\n",
        "\t\t\txmin = max(-0.5,(im_boxes[k,0]) - 0.5)\n",
        "\t\t\tymin = max(-0.5,(im_boxes[k,1]) - 0.5)\n",
        "\t\t\txmax = min(image_size-0.5,(im_boxes[k,2]) - 0.5)\n",
        "\t\t\tymax = min(image_size-0.5,(im_boxes[k,3]) - 0.5)\n",
        "\t\t\t\n",
        "\t\t\tp_c = np.argmax(im_boxes[k,7:])\n",
        "\t\t\t\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=1.0, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\t\t\tc_patch = ax[i,j].add_patch(el)\n",
        "\t\t\tc_text = ax[i,j].text(xmin+5, ymin+18, \"%s:%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=4,clip_on=True)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=2.0, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\t\t\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kxg4VgJIoNHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## A runtime restart is advised"
      ],
      "metadata": {
        "id": "rDWzWQYa4qWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### mAP maximization\n",
        "\n",
        "**Note:** Using the following selection, the pre-trained network reaches an mAP of 36% when applied to the complete 4952 test set. The achieved mAP is only 33% on the last 1000 test examples in the present case due to a selection effect."
      ],
      "metadata": {
        "id": "bdi8VZUayYp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IRMIA_2022/yolo_detector/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib import patches\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import re\n",
        "import bisect\n",
        "import os\n",
        "import sys\n",
        "from numba import jit\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "class_list_short = np.array([\"plane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"table\",\"dog\",\"horse\", \"m-bike\",\\\n",
        "    \"person\",\"p-plant\",\"sheep\",\"sofa\",\"train\",\"tv\",\"background\"])\n",
        "\n",
        "test_list = np.loadtxt(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "nb_train_2012 = 11540\n",
        "nb_train_2007 = 5011\n",
        "nb_test_2007 = 4952\n",
        "orig_nb_images = 11540 + 5011 + 4952\n",
        "nb_keep_val = 1000\n",
        "\n",
        "image_size = 288\n",
        "nb_box = 5\n",
        "nb_class = 20\n",
        "nb_param = 0\n",
        "\n",
        "max_nb_obj_per_image = 48\n",
        "\n",
        "yolo_nb_reg = int(image_size/32)\n",
        "c_size = 32\n",
        "\n",
        "all_im = np.fromfile(\"/content/IRMIA_2022/datasets/all_im.dat\", dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(\"/content/IRMIA_2022/datasets/all_im_prop.dat\", dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((orig_nb_images, image_size, image_size, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(orig_nb_images, 4))\n",
        "\n",
        "load_epoch = 0\t\n",
        "if(load_epoch == 0):\n",
        "\tfiles = os.listdir(\"fwd_res/\")\n",
        "\tpaths = [os.path.join(\"fwd_res/\", basename) for basename in files]\n",
        "\tpath = max(paths, key=os.path.getctime)\n",
        "\tr_load_epoch = [int(s) for s in re.split('[_s.]',path) if s.isdigit()]\n",
        "\tprint (r_load_epoch)\n",
        "\tprint(\"Epoch unspecified, loading most recent prediction : \" + path)\n",
        "\t\n",
        "\tload_epoch = r_load_epoch[0]\n",
        "\n",
        "prior_w = np.array([24.,48.,96.,144.,256.])\n",
        "prior_h = np.array([24.,64.,176.,80.,192.])\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (nb_keep_val, nb_box*(8+nb_param+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "targets = np.zeros((nb_keep_val,1+max_nb_obj_per_image*7), dtype=\"float32\")\n",
        "\n",
        "class_count = np.zeros((nb_class))\n",
        "\n",
        "for i in tqdm(range(0, nb_keep_val)):\n",
        "\ti_d = nb_test_2007 - nb_keep_val + i\n",
        "\t\n",
        "\ttree = ET.parse(\"/content/IRMIA_2022/datasets/VOCdevkit/VOC2007/Annotations/\"+test_list[i_d]+\".xml\")\n",
        "\troot = tree.getroot()\n",
        "\t\n",
        "\tx_offset, y_offset, width2, height2 = all_im_prop[nb_train_2012 + nb_train_2007 + i_d ]\n",
        "\t\n",
        "\tk = 0\n",
        "\tobj_list = root.findall(\"object\", namespaces=None)\n",
        "\ttargets[i,0] = len(obj_list)\n",
        "\tfor obj in obj_list:\n",
        "\t\tdiff = obj.find(\"difficult\", namespaces=None)\n",
        "\t\tif(diff.text == \"1\"):\n",
        "\t\t\ttargets[i,0] -= 1\n",
        "\t\t\tcontinue\n",
        "\t\toclass = obj.find(\"name\", namespaces=None)\n",
        "\t\tbndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "\t\tint_class = np.where(class_list[:] == oclass.text)\n",
        "\t\txmin = int(float(bndbox.find(\"xmin\").text)+x_offset)*image_size/width2\n",
        "\t\tymin = int(float(bndbox.find(\"ymin\").text)+y_offset)*image_size/height2\n",
        "\t\txmax = int(float(bndbox.find(\"xmax\").text)+x_offset)*image_size/width2\n",
        "\t\tymax = int(float(bndbox.find(\"ymax\").text)+y_offset)*image_size/height2\n",
        "\n",
        "\t\ttargets[i,1+k*7:1+(k+1)*7] = np.array([int_class[0][0]+1, xmin,ymin,0.0,xmax,ymax,1.0])\n",
        "\t\tclass_count[int_class[0][0]] += 1\n",
        "\t\t\n",
        "\t\tk += 1\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def global_to_tile_coord(offset_tab, tile_coords, priors, c_size):\n",
        "\tbx = (offset_tab[0] + tile_coords[1])*c_size\n",
        "\tby = (offset_tab[1] + tile_coords[0])*c_size\n",
        "\tbw = priors[0]*np.exp(offset_tab[3])\n",
        "\tbh = priors[1]*np.exp(offset_tab[4])\n",
        "\treturn float(bx), float(by), float(bw), float(bh)\n",
        " \n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def box_extraction(c_pred, c_box, c_tile, prob_obj_cases, class_soft_limit):\n",
        "  c_nb_box = 0\n",
        "  for i in range(0,yolo_nb_reg):\n",
        "    for j in range(0,yolo_nb_reg):\n",
        "      for k in range(0,nb_box):\n",
        "        offset = int(k*(8+nb_param+nb_class)) #no +1 for box prior in prediction\n",
        "        c_box[4] = c_pred[offset+6,i,j]\n",
        "        c_box[5] = c_pred[offset+7,i,j]\n",
        "        p_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "        cl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j]) \n",
        "        \n",
        "        if(c_box[5]*p_c >= prob_obj_cases[k] and p_c > class_soft_limit[0]):\n",
        "          bx, by, bw, bh = global_to_tile_coord(c_pred[offset:offset+6,i,j], \\\n",
        "                    np.array([i,j]), np.array([prior_w[k], prior_h[k]]), c_size)\n",
        "          c_box[0] = max(0,bx - bw*0.5 - 1)\n",
        "          c_box[1] = max(0,by - bh*0.5 - 1)\n",
        "          c_box[2] = min(image_size,bx + bw*0.5 + 1)\n",
        "          c_box[3] = min(image_size,by + bh*0.5 + 1)\n",
        "          \n",
        "          c_box[6] = k\n",
        "          c_box[7:] = c_pred[offset+8:offset+8+nb_param+nb_class,i,j]\n",
        "          c_tile[c_nb_box,:] = c_box[:]\n",
        "          c_nb_box +=1\n",
        "\n",
        "  return c_nb_box\n",
        "\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\tenclose_w = (max(box1[2], box2[2]) - min(box1[0], box2[0]))\n",
        "\tenclose_h = (max(box1[3], box2[3]) - min(box1[1],box2[1]))\n",
        "\tenclose_2d = enclose_w*enclose_h\n",
        "\n",
        "\tcx_a = (box1[2] + box1[0])*0.5; cx_b = (box2[2] + box2[0])*0.5\n",
        "\tcy_a = (box1[3] + box1[1])*0.5; cy_b = (box2[3] + box2[1])*0.5\n",
        "\tdist_cent = np.sqrt((cx_a - cx_b)*(cx_a - cx_b) + (cy_a - cy_b)*(cy_a - cy_b))\n",
        "\tdiag_enclose = np.sqrt(enclose_w*enclose_w + enclose_h*enclose_h)\n",
        "\n",
        "  # DIoU\n",
        "\t#return float(inter_2d)/float(uni_2d) - float(dist_cent)/float(diag_enclose)\n",
        "  # GIoU\n",
        "\treturn float(inter_2d)/float(uni_2d) - float(enclose_2d - uni_2d)/float(enclose_2d)\n",
        "\t\n",
        "@jit(nopython=True, cache=True, fastmath=False)\n",
        "def fct_classical_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]))\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]))\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0])*abs(box1[3] - box1[1]) + \\\n",
        "\t\tabs(box2[2]-box2[0])*abs(box2[3] - box2[1]) - inter_2d\n",
        "\n",
        "\treturn float(inter_2d)/float(uni_2d)\n",
        "\n",
        "\n",
        "#@jit(nopython=True, cache=True, fastmath=False)\n",
        "def apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold):\n",
        "  c_nb_box_final = 0\n",
        "  c_box_size_prev = c_nb_box\n",
        "\n",
        "  while(c_nb_box > 0):\n",
        "    max_objct = np.argmax(c_tile[:c_box_size_prev,5]*np.amax(c_tile[:c_box_size_prev,7:], axis=1))\n",
        "    c_box = np.copy(c_tile[max_objct])\n",
        "    c_tile[max_objct,5] = 0.0\n",
        "    c_tile_kept[c_nb_box_final] = c_box\n",
        "    c_nb_box_final += 1\n",
        "    c_nb_box -= 1\n",
        "    i = 0\n",
        "    for i in range(0,c_box_size_prev):\n",
        "      if(c_tile[i,5] < 0.00000001):\n",
        "        continue\n",
        "      IoU = fct_IoU(c_box[:4], c_tile[i,:4])\n",
        "      c_score = c_tile[i,5]*np.max(c_tile[i,7:])\n",
        "      \n",
        "      if((IoU > 0.3 and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]) and c_score >= 0.9)\n",
        "        or (IoU > 0.3 and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]) and c_score < 0.9 and c_score >= 0.1)\n",
        "        or (IoU > 0.4 and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]) and c_score >= 0.8)\n",
        "        or (IoU > 0.4 and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]) and c_score < 0.8 and c_score >= 0.1)\n",
        "        or (IoU > -0.6 and c_score < 0.1)):\n",
        "        c_tile[i] = 0.0\n",
        "        c_nb_box -= 1\n",
        "     \n",
        "  return c_nb_box_final\n",
        "\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+nb_class),dtype=\"float32\")\n",
        "patch = np.zeros((image_size, image_size), dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "#Choice of filters that produce visually appealing results (!= best mAP )\n",
        "obj_threshold = 0.5*np.array([0.1,0.1,0.1,0.1,0.1])\n",
        "class_soft_limit = np.array([0.4])\n",
        "\n",
        "nms_threshold = 0.1 \n",
        "#Not used here, context dependant thresholds are defined in the NMS fct\n",
        "\n",
        "for l in tqdm(range(0,nb_keep_val)):\n",
        "\tc_tile[:,:] = 0.0\n",
        "\tc_tile_kept[:,:] = 0.0\n",
        "\n",
        "\tc_pred = predict[l,:,:,:]\n",
        "\tc_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\t\t\t\n",
        "\n",
        "\tc_nb_box_final = c_nb_box\n",
        "\tc_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, nms_threshold)\n",
        "\tfinal_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        " \n",
        "flat_pred_boxes = np.vstack(final_boxes)\n",
        "\n",
        "AP_IoU_val = 0.5\n",
        "\n",
        "recall_precision = np.empty((nb_keep_val), dtype=\"object\")\n",
        "\n",
        "print(\"Find associations ...\", flush=True)\n",
        "\n",
        "for i_d in tqdm(range(0, nb_keep_val)):\n",
        "\t\t\t\t\n",
        "\trecall_precision[i_d] = np.zeros((np.shape(final_boxes[i_d])[0], 6))\n",
        "\t\n",
        "\tif(np.shape(final_boxes[i_d])[0] == 0):\n",
        "\t\tcontinue\n",
        "\t\n",
        "\trecall_precision[i_d][:,0] = np.amax(final_boxes[i_d][:,7:], axis=1)\n",
        "\trecall_precision[i_d][:,1] = final_boxes[i_d][:,5]\n",
        "\t\n",
        "\trecall_precision[i_d][:,5] = np.argmax(final_boxes[i_d][:,7:], axis=1)\n",
        "\t\n",
        "\tkept_boxes = targets[i_d]\n",
        "\t\n",
        "\tIoU_table = np.zeros((int(kept_boxes[0]),np.shape(final_boxes[i_d])[0])) - 1.0\n",
        "\t\n",
        "\tfor i in range(0,int(kept_boxes[0])):\n",
        "\t\tfor j in range(0,np.shape(final_boxes[i_d])[0]):\n",
        "\t\t\txmin = (kept_boxes[1+i*7+1])\n",
        "\t\t\tymin = (kept_boxes[1+i*7+2])\n",
        "\t\t\txmax = (kept_boxes[1+i*7+4])\n",
        "\t\t\tymax = (kept_boxes[1+i*7+5])\n",
        "\t\t\tc_kept_box = np.array([xmin, ymin, xmax, ymax])\n",
        "\t\t\tIoU_table[i,j] = fct_classical_IoU(c_kept_box, final_boxes[i_d][j,:4])\n",
        "\t\t\t\n",
        "\t# Loop over the true boxes to find best prediction associated\n",
        "\tfor i in range(0,int(kept_boxes[0])):\n",
        "\t\tbest_match_id = np.unravel_index(np.argmax(IoU_table),np.shape(IoU_table))\n",
        "\t\t\n",
        "\t\tbest_match_IoU = IoU_table[best_match_id]\n",
        "\t\t\n",
        "\t\tIoU_table[best_match_id[0],:] = -1.0\n",
        "\t\t\n",
        "\t\tif (best_match_IoU >= AP_IoU_val and np.argmax(final_boxes[i_d][best_match_id[1],7:]) == int(kept_boxes[1+best_match_id[0]*7+0]-1)):\n",
        "\t\t#if(c_IoU >= AP_IoU_val):\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],2] = 1\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],3] = best_match_id[1]\n",
        "\t\t\trecall_precision[i_d][best_match_id[1],4] = best_match_IoU\n",
        "\t\t\tIoU_table[:,best_match_id[1]] = -1.0\n",
        "\t\t\n",
        "\n",
        "print(\"Process and flatten the mAP result\")\n",
        "flatten = np.vstack(recall_precision.flatten())\n",
        "\n",
        "recall_precision_f = np.zeros((np.shape(flatten)[0], 10))\n",
        "recall_precision_f[:,:6] = flatten[:,:]\n",
        "\n",
        "recall_precision_fs = (recall_precision_f[(recall_precision_f[:,1]*recall_precision_f[:,0]).argsort()])[::-1]\n",
        "\n",
        "recall_precision_fs[:,6] = np.cumsum(recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,7] = np.cumsum(1.0 - recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,8] = recall_precision_fs[:,6] / (recall_precision_fs[:,6]+recall_precision_fs[:,7])\n",
        "recall_precision_fs[:,9] = recall_precision_fs[:,6] / np.sum(class_count)\n",
        "\n",
        "\n",
        "interp_curve = np.zeros((np.shape(recall_precision_fs)[0],2))\n",
        "\n",
        "interp_curve[:,0] = recall_precision_fs[:,9]\n",
        "#Go in reverse to set the value for the all point interpolation\n",
        "c_max_val = np.min(recall_precision_fs[:,8])\n",
        "for i in range(0, np.shape(recall_precision_fs)[0]):\n",
        "    i_d = np.shape(recall_precision_fs)[0] - i - 1\n",
        "    if(recall_precision_fs[i_d,8] > c_max_val):\n",
        "        c_max_val = recall_precision_fs[i_d,8]\n",
        "    interp_curve[i_d,1] = c_max_val\n",
        "    \n",
        "\n",
        "AP_all = np.trapz(interp_curve[:,1], interp_curve[:,0])\n",
        "print (\"AP_all (%.2f): %f%%\"%(AP_IoU_val, AP_all*100.0))\n",
        "\n",
        "    \n",
        "plt.figure(figsize=(4*1.0,3*1.0), dpi=200, constrained_layout=True)\n",
        "plt.plot(recall_precision_fs[:,9], recall_precision_fs[:,8])\n",
        "plt.plot(interp_curve[:,0], interp_curve[:,1], label=\"New\")\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "plt.title(\"All classes as one AP curve\", fontsize=8)\n",
        "\n",
        "#print (class_count)\n",
        "sumAP = 0\n",
        "print (\"**** Per class AP ****\")\n",
        "fig, ax = plt.subplots(figsize=(4*1.3,3*1.3), dpi=200, constrained_layout=True)\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "for k in range(0, nb_class):\n",
        "\tindex = np.where(recall_precision_fs[:,5] == k)\n",
        "\tl_recall_precision_fs = recall_precision_fs[index[0]]\n",
        "\tl_recall_precision_fs[:,6] = np.cumsum(l_recall_precision_fs[:,2])\n",
        "\tl_recall_precision_fs[:,7] = np.cumsum(1.0 - l_recall_precision_fs[:,2])\n",
        "\tl_recall_precision_fs[:,8] = l_recall_precision_fs[:,6] / (l_recall_precision_fs[:,6]+l_recall_precision_fs[:,7])\n",
        "\tl_recall_precision_fs[:,9] = l_recall_precision_fs[:,6] / class_count[k]\n",
        "\t\n",
        "\tinterp_curve = np.zeros((np.shape(index[0])[0],2))\n",
        "\n",
        "\tinterp_curve[:,0] = l_recall_precision_fs[:,9]\n",
        "\t#Go in reverse to set the value for the all point interpolation\n",
        "\tc_max_val = np.min(l_recall_precision_fs[:,8])\n",
        "\tfor i in range(0, np.shape(l_recall_precision_fs)[0]):\n",
        "\t\ti_d = np.shape(l_recall_precision_fs)[0] - i - 1\n",
        "\t\tif(l_recall_precision_fs[i_d,8] > c_max_val):\n",
        "\t\t\tc_max_val = l_recall_precision_fs[i_d,8]\n",
        "\t\tinterp_curve[i_d,1] = c_max_val\n",
        "\t\n",
        "\tAP = np.trapz(interp_curve[:,1], interp_curve[:,0])\n",
        "\tsumAP += AP\n",
        "\t\n",
        "\tplt.plot(interp_curve[:,0], interp_curve[:,1], label=class_list_short[k],c=plt.cm.tab20(k))\n",
        "\t\n",
        "\tprint(\"AP %-8s: %5.2f%%     Total: %4d - T: %4d - F: %4d\"%(class_list_short[k], AP*100.0, class_count[k], l_recall_precision_fs[-1,6], l_recall_precision_fs[-1,7]))\n",
        "plt.legend(bbox_to_anchor=(1.02,0.98), fontsize=8)\n",
        "plt.title(\"Per class AP curve\", fontsize=8)\n",
        "\n",
        "print (\"\\n**** mAP (%.2f): %f%% ****\"%(AP_IoU_val, sumAP/nb_class*100.0))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wEVrvn_Eycpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
